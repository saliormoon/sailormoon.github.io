
 <!DOCTYPE HTML>
<html >
<head>
  <meta charset="UTF-8">
  
    <title>Scrapy安装及使用 | 刘兴的博客</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="刘兴">
    

    
    <meta name="description" content="本文介绍了常见的网络爬虫工具Scrapy的安装及使用过程，另外介绍了Scrapy运行时常见问题以及相应解决办法，希望能对您的学习带来帮助。">
<meta property="og:type" content="article">
<meta property="og:title" content="Scrapy安装及使用">
<meta property="og:url" content="http://pangjiuzala.github.io/2015/07/22/Scrapy安装及使用/index.html">
<meta property="og:site_name" content="刘兴的博客">
<meta property="og:description" content="本文介绍了常见的网络爬虫工具Scrapy的安装及使用过程，另外介绍了Scrapy运行时常见问题以及相应解决办法，希望能对您的学习带来帮助。">
<meta property="og:image" content="http://7xiur2.com1.z0.glb.clouddn.com/0045.png">
<meta property="og:image" content="http://7xiur2.com1.z0.glb.clouddn.com/0046.png">
<meta property="og:image" content="http://7xiur2.com1.z0.glb.clouddn.com/0048.png">
<meta property="og:updated_time" content="2015-07-29T07:20:37.361Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Scrapy安装及使用">
<meta name="twitter:description" content="本文介绍了常见的网络爬虫工具Scrapy的安装及使用过程，另外介绍了Scrapy运行时常见问题以及相应解决办法，希望能对您的学习带来帮助。">

    
    <link rel="alternative" href="https://github.com/search?q=pangjiuzala&type=Users" title="刘兴的博客" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css" type="text/css">
</head>

  <body>
    <header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.png" alt="刘兴的博客" title="刘兴的博客"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="刘兴的博客">刘兴的博客</a></h1>
				<h2 class="blog-motto"></h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">主页</a></li>
					
						<li><a href="/archives">文章列表</a></li>
					
					<li>
 					
					<form class="search" action="/search/index.html" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" autocomplete="off" name="q" maxlength="20" placeholder="搜索" />
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
  
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2015/07/22/Scrapy安装及使用/" title="Scrapy安装及使用" itemprop="url">Scrapy安装及使用</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="刘兴" target="_blank" itemprop="author">刘兴</a>
		
  <p class="article-time">
    <time datetime="2015-07-22T11:44:53.000Z" itemprop="datePublished"> 发表于 2015-07-22</time>
    
  </p>
</header>
	<div class="article-content">
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">文章目录</strong>
		
			<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Scrapy简介"><span class="toc-number">1.</span> <span class="toc-text">Scrapy简介</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#安装Python2-7"><span class="toc-number">2.</span> <span class="toc-text">安装Python2.7</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#安装python"><span class="toc-number">2.1.</span> <span class="toc-text">安装python</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#添加环境变量"><span class="toc-number">2.2.</span> <span class="toc-text">添加环境变量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#验证环境变量"><span class="toc-number">2.3.</span> <span class="toc-text">验证环境变量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#验证Python"><span class="toc-number">2.4.</span> <span class="toc-text">验证Python</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#安装Scrapy"><span class="toc-number">3.</span> <span class="toc-text">安装Scrapy</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#生成项目"><span class="toc-number">4.</span> <span class="toc-text">生成项目</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#将数据保存到mysql数据库"><span class="toc-number">5.</span> <span class="toc-text">将数据保存到mysql数据库</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#数据库建表语句"><span class="toc-number">5.1.</span> <span class="toc-text">数据库建表语句</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#中文乱码问题"><span class="toc-number">5.2.</span> <span class="toc-text">中文乱码问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#配置pipelines-py"><span class="toc-number">5.3.</span> <span class="toc-text">配置pipelines.py</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#配置setting-py"><span class="toc-number">5.4.</span> <span class="toc-text">配置setting.py</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#执行scrapy_crawl_dmoz"><span class="toc-number">5.5.</span> <span class="toc-text">执行scrapy crawl dmoz</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Python脚本运行出现语法错误"><span class="toc-number">6.</span> <span class="toc-text">Python脚本运行出现语法错误</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#生成的json文件编码默认为Unicode"><span class="toc-number">7.</span> <span class="toc-text">生成的json文件编码默认为Unicode</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#配置pipelines-py文件"><span class="toc-number">7.1.</span> <span class="toc-text">配置pipelines.py文件</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#配置settings-py文件"><span class="toc-number">7.2.</span> <span class="toc-text">配置settings.py文件</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#使用Beautiful_Soup"><span class="toc-number">8.</span> <span class="toc-text">使用Beautiful Soup</span></a></li></ol>
		
		</div>
		
		<p>  本文介绍了常见的网络爬虫工具<strong><strong>Scrapy的安装及使用过程</strong></strong>，另外介绍了Scrapy运行时常见问题以及相应解决办法，希望能对您的学习带来帮助。<br><a id="more"></a></p>
<h1 id="Scrapy简介">Scrapy简介</h1><p> Scrapy是一个快速高级屏幕抓取和爬行网页的框架，用来抓取的网站，从网页中抽取结构化的数据。它可以用于广泛的用途，从数据挖掘到监控和自动化测试。</p>
<p>官方主页： <a href="http://www.scrapy.org/" target="_blank" rel="external">http://www.scrapy.org/</a></p>
<h1 id="安装Python2-7">安装Python2.7</h1><p>官方主页：<a href="http://www.python.org/" target="_blank" rel="external">http://www.python.org/</a></p>
<p>下载地址：<a href="http://www.python.org/ftp/python/2.7.3/python-2.7.3.msi" target="_blank" rel="external">http://www.python.org/ftp/python/2.7.3/python-2.7.3.msi</a></p>
<h2 id="安装python">安装python</h2><p>安装目录：D:\Python27</p>
<h2 id="添加环境变量">添加环境变量</h2><p>略System Properties -&gt; Advanced -&gt; Environment Variables - &gt;System Variables -&gt; Path -&gt; Edit</p>
<h2 id="验证环境变量">验证环境变量</h2><figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="rule"><span class="attribute">T</span>:<span class="value">\&gt;set Path</span><br><span class="line">Path=C:\WINDOWS\system32</span></span>;<span class="rule"><span class="attribute">C</span>:<span class="value">\WINDOWS</span></span>;<span class="rule"><span class="attribute">C</span>:<span class="value">\WINDOWS\System32\Wbem</span></span>;<span class="rule"><span class="attribute">D</span>:<span class="value">\Rational\common</span></span>;<span class="rule"><span class="attribute">D</span>:<span class="value">\Rational\ClearCase\bin</span></span>;<span class="rule"><span class="attribute">D</span>:<span class="value">\Python27</span></span>;<span class="rule"><span class="attribute">D</span>:<span class="value">\Python27\Scripts</span><br><span class="line">PATHEXT=.COM</span></span>;<span class="class">.EXE</span>;<span class="class">.BAT</span>;<span class="class">.CMD</span>;<span class="class">.VBS</span>;<span class="class">.VBE</span>;<span class="class">.JS</span>;<span class="class">.JSE</span>;<span class="class">.WSF</span>;<span class="class">.WSH</span></span><br></pre></td></tr></table></figure>
<h2 id="验证Python">验证Python</h2><figure class="highlight vhdl"><table><tr><td class="code"><pre><span class="line">T:\&gt;python</span><br><span class="line">Python <span class="number">2.7</span>.<span class="number">3</span> (<span class="keyword">default</span>, Apr <span class="number">10</span> <span class="number">2012</span>, <span class="number">23</span>:<span class="number">31</span>:<span class="number">26</span>) [MSC v.<span class="number">1500</span> <span class="number">32</span> <span class="typename">bit</span> (Intel)] <span class="keyword">on</span> win32</span><br><span class="line"><span class="keyword">Type</span> <span class="string">"help"</span>, <span class="string">"copyright"</span>, <span class="string">"credits"</span> <span class="keyword">or</span> <span class="string">"license"</span> <span class="keyword">for</span> more information.</span><br><span class="line">&gt;&gt;&gt; <span class="keyword">exit</span>()</span><br><span class="line"></span><br><span class="line">T:\&gt;</span><br></pre></td></tr></table></figure>
<h1 id="安装Scrapy">安装Scrapy</h1><p>官方主页：<a href="http://scrapy.org/" target="_blank" rel="external">http://scrapy.org/</a></p>
<p>下载地址：<a href="http://pypi.python.org/packages/source/S/Scrapy/Scrapy-0.14.4.tar.gz" target="_blank" rel="external">http://pypi.python.org/packages/source/S/Scrapy/Scrapy-0.14.4.tar.gz</a></p>
<p>解压过程：略</p>
<p>安装过程：<br><figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">T:<span class="command">\Scrapy</span>-0.14.4&gt;python setup.py install</span><br><span class="line"></span><br><span class="line">……</span><br><span class="line">Installing easy_install-2.7-script.py script to D:<span class="command">\Python</span>27<span class="command">\Scripts</span></span><br><span class="line">Installing easy_install-2.7.exe script to D:<span class="command">\Python</span>27<span class="command">\Scripts</span></span><br><span class="line">Installing easy_install-2.7.exe.manifest script to D:<span class="command">\Python</span>27<span class="command">\Scripts</span></span><br><span class="line"></span><br><span class="line">Using d:<span class="command">\python</span>27<span class="command">\lib</span><span class="command">\site</span>-packages</span><br><span class="line">Finished processing dependencies for Scrapy==0.14.4</span><br><span class="line"></span><br><span class="line">T:<span class="command">\Scrapy</span>-0.14.4&gt;</span><br></pre></td></tr></table></figure></p>
<p>验证安装：<br><figure class="highlight livecodeserver"><table><tr><td class="code"><pre><span class="line">T:\&gt;scrapy</span><br><span class="line">Scrapy <span class="number">0.14</span>.4 - no active project</span><br><span class="line"></span><br><span class="line">Usage:</span><br><span class="line">  scrapy &lt;<span class="command"><span class="keyword">command</span>&gt; [<span class="title">options</span>] [<span class="title">args</span>]</span></span><br><span class="line"></span><br><span class="line">Available commands:</span><br><span class="line">  fetch         Fetch <span class="operator">a</span> <span class="built_in">URL</span> <span class="keyword">using</span> <span class="operator">the</span> Scrapy downloader</span><br><span class="line">  runspider     Run <span class="operator">a</span> self-contained spider (<span class="keyword">without</span> creating <span class="operator">a</span> project)</span><br><span class="line">  settings      Get settings values</span><br><span class="line">  <span class="built_in">shell</span>         Interactive scraping console</span><br><span class="line">  startproject  Create <span class="built_in">new</span> project</span><br><span class="line">  <span class="built_in">version</span>       Print Scrapy <span class="built_in">version</span></span><br><span class="line">  view          Open <span class="built_in">URL</span> <span class="operator">in</span> browser, <span class="keyword">as</span> seen <span class="keyword">by</span> Scrapy</span><br><span class="line"></span><br><span class="line">Use <span class="string">"scrapy &lt;command&gt; -h"</span> <span class="built_in">to</span> see more info about <span class="operator">a</span> <span class="command"><span class="keyword">command</span></span></span><br><span class="line"></span><br><span class="line">T:\&gt;</span><br></pre></td></tr></table></figure></p>
<h1 id="生成项目">生成项目</h1><p>scrapy提供一个工具来生成项目，生成的项目中预置了一些文件，用户需要在这些文件中添加自己的代码。<br>打开命令行，执行：scrapy startproject tutorial，生成的项目类似下面的结构<br>tutorial/<br>   scrapy.cfg<br>   tutorial/<br>       <strong>init</strong>.py<br>       items.py<br>       pipelines.py<br>       settings.py<br>       spiders/<br>           <strong>init</strong>.py<br>           …<br>scrapy.cfg是项目的配置文件<br>用户自己写的spider要放在spiders目录下面，建立一个dmoz.py文件,如下图</p>
<center><img src="http://7xiur2.com1.z0.glb.clouddn.com/0045.png" alt=""></center>

<p>内容如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.spider <span class="keyword">import</span> BaseSpider</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DmozSpider</span><span class="params">(BaseSpider)</span>:</span></span><br><span class="line">    name = <span class="string">"dmoz"</span></span><br><span class="line">    allowed_domains = [<span class="string">"dmoz.org"</span>]</span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">"http://pangjiuzala.github.io/"</span></span><br><span class="line">       </span><br><span class="line">    ]</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        filename = response.url.split(<span class="string">"/"</span>)[-<span class="number">2</span>]</span><br><span class="line">        open(filename, <span class="string">'wb'</span>).write(response.body)</span><br></pre></td></tr></table></figure>
<p>name属性很重要，不同spider不能使用相同的name<br>start_urls是spider抓取网页的起始点，可以包括多个url<br>parse方法是spider抓到一个网页以后默认调用的callback，避免使用这个名字来定义自己的方法。<br>当spider拿到url的内容以后，会调用parse方法，并且传递一个response参数给它，response包含了抓到的网页的内容，在parse方法里，你可以从抓到的网页里面解析数据。上面的代码只是简单地把网页内容保存到文件。<br>开始抓取<br>你可以打开命令行，进入生成的项目根目录tutorial/，执行 scrapy crawl dmoz， dmoz是spider的name。<br>解析网页内容<br>scrapy提供了方便的办法从网页中解析数据，这需要使用到HtmlXPathSelector<br><figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">from scrapy<span class="class">.spider</span> import BaseSpider</span><br><span class="line">from scrapy<span class="class">.selector</span> import HtmlXPathSelector</span><br><span class="line">class <span class="function"><span class="title">DmozSpider</span><span class="params">(BaseSpider)</span></span>:</span><br><span class="line">    name = <span class="string">"dmoz"</span></span><br><span class="line">    allowed_domains = [<span class="string">"dmoz.org"</span>]</span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">"http://pangjiuzala.github.io/"</span></span><br><span class="line"></span><br><span class="line">    ]</span><br><span class="line">    def <span class="function"><span class="title">parse</span><span class="params">(self, response)</span></span>:</span><br><span class="line">        hxs = <span class="function"><span class="title">HtmlXPathSelector</span><span class="params">(response)</span></span></span><br><span class="line">        sites = hxs.<span class="function"><span class="title">select</span><span class="params">(<span class="string">'//ul/li'</span>)</span></span></span><br><span class="line">        <span class="keyword">for</span> site <span class="keyword">in</span> sites:</span><br><span class="line">            title = site.<span class="function"><span class="title">select</span><span class="params">(<span class="string">'a/text()'</span>)</span></span>.<span class="function"><span class="title">extract</span><span class="params">()</span></span></span><br><span class="line">            link = site.<span class="function"><span class="title">select</span><span class="params">(<span class="string">'a/@href'</span>)</span></span>.<span class="function"><span class="title">extract</span><span class="params">()</span></span></span><br><span class="line">            desc = site.<span class="function"><span class="title">select</span><span class="params">(<span class="string">'text()'</span>)</span></span>.<span class="function"><span class="title">extract</span><span class="params">()</span></span></span><br><span class="line">            print title, link, desc</span><br></pre></td></tr></table></figure></p>
<p>HtmlXPathSelector使用了Xpath来解析数据<br>//ul/li表示选择所有的ul标签下的li标签<br>a/@href表示选择所有a标签的href属性<br>a/text()表示选择a标签文本<br>a[@href=”abc”]表示选择所有href属性是abc的a标签<br>我们可以把解析出来的数据保存在一个scrapy可以使用的对象中，然后scrapy可以帮助我们把这些对象保存起来，而不用我们自己把这些数据存到文件中。我们需要在items.py中添加一些类，这些类用来描述我们要保存的数据<br><figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">from scrapy<span class="class">.item</span> import Item, Field</span><br><span class="line">class <span class="function"><span class="title">DmozItem</span><span class="params">(Item)</span></span>:</span><br><span class="line">   title = <span class="function"><span class="title">Field</span><span class="params">()</span></span></span><br><span class="line">   link = <span class="function"><span class="title">Field</span><span class="params">()</span></span></span><br><span class="line">   desc = <span class="function"><span class="title">Field</span><span class="params">()</span></span></span><br></pre></td></tr></table></figure></p>
<p>然后在spider的parse方法中，我们把解析出来的数据保存在DomzItem对象中。<br><figure class="highlight haskell"><table><tr><td class="code"><pre><span class="line"><span class="title">from</span> scrapy.spider <span class="import"><span class="keyword">import</span> BaseSpider</span></span><br><span class="line"><span class="title">from</span> scrapy.selector <span class="import"><span class="keyword">import</span> HtmlXPathSelector</span></span><br><span class="line"><span class="title">from</span> tutorial.items <span class="import"><span class="keyword">import</span> DmozItem</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="type">DmozSpider</span><span class="container">(<span class="type">BaseSpider</span>)</span>:</span><br><span class="line">   name = "dmoz"</span><br><span class="line">   allowed_domains = ["dmoz.org"]</span><br><span class="line">   start_urls = [</span><br><span class="line">       "http://pangjiuzala.github.io/       </span><br><span class="line">   ]</span><br><span class="line">   def parse<span class="container">(<span class="title">self</span>, <span class="title">response</span>)</span>:</span><br><span class="line">       hxs = <span class="type">HtmlXPathSelector</span><span class="container">(<span class="title">response</span>)</span></span><br><span class="line">       sites = hxs.select<span class="container">('//<span class="title">ul</span>/<span class="title">li'</span>)</span></span><br><span class="line">       items = []</span><br><span class="line">       for site in sites:</span><br><span class="line">           item = <span class="type">DmozItem</span><span class="container">()</span></span><br><span class="line">           item['title'] = site.select<span class="container">('<span class="title">a</span>/<span class="title">text</span>()</span>').extract<span class="container">()</span></span><br><span class="line">           item['link'] = site.select<span class="container">('<span class="title">a</span>/@<span class="title">href'</span>)</span>.extract<span class="container">()</span></span><br><span class="line">           item['desc'] = site.select<span class="container">('<span class="title">text</span>()</span>').extract<span class="container">()</span></span><br><span class="line">           items.append<span class="container">(<span class="title">item</span>)</span></span><br><span class="line">       return items</span></span><br></pre></td></tr></table></figure></p>
<p>在命令行执行scrapy的时候，我们可以加两个参数，让scrapy把parse方法返回的items输出到json文件中<br>scrapy crawl dmoz -o items.json -t json<br>items.json会被放在项目的根目录<br>让scrapy自动抓取网页上的所有链接<br>上面的示例中scrapy只抓取了start_urls里面的两个url的内容，但是通常我们想实现的是scrapy自动发现一个网页上的所有链接，然后再去抓取这些链接的内容。为了实现这一点我们可以在parse方法里面提取我们需要的链接，然后构造一些Request对象，并且把他们返回，scrapy会自动的去抓取这些链接。代码类似：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySpider</span><span class="params">(BaseSpider)</span>:</span></span><br><span class="line">    name = <span class="string">'myspider'</span></span><br><span class="line">    start_urls = (</span><br><span class="line">        <span class="string">'http://example.com/page1'</span>,</span><br><span class="line">        <span class="string">'http://example.com/page2'</span>,</span><br><span class="line">        )</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="comment"># collect `item_urls`</span></span><br><span class="line">        <span class="keyword">for</span> item_url <span class="keyword">in</span> item_urls:</span><br><span class="line">            <span class="keyword">yield</span> Request(url=item_url, callback=self.parse_item)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        item = MyItem()</span><br><span class="line">        <span class="comment"># populate `item` fields</span></span><br><span class="line">        <span class="keyword">yield</span> Request(url=item_details_url, meta=&#123;<span class="string">'item'</span>: item&#125;,</span><br><span class="line">            callback=self.parse_details)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_details</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        item = response.meta[<span class="string">'item'</span>]</span><br><span class="line">        <span class="comment"># populate more `item` fields</span></span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure></p>
<p>parse是默认的callback, 它返回了一个Request列表，scrapy自动的根据这个列表抓取网页，每当抓到一个网页，就会调用parse_item，parse_item也会返回一个列表，scrapy又会根据这个列表去抓网页，并且抓到后调用parse_details<br>为了让这样的工作更容易，scrapy提供了另一个spider基类，利用它我们可以方便的实现自动抓取链接. 我们要用到CrawlSpider<br><figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">from scrapy<span class="class">.contrib</span><span class="class">.linkextractors</span><span class="class">.sgml</span> import SgmlLinkExtractor</span><br><span class="line">class <span class="function"><span class="title">MininovaSpider</span><span class="params">(CrawlSpider)</span></span>:</span><br><span class="line">    name = <span class="string">'mininova.org'</span></span><br><span class="line">    allowed_domains = [<span class="string">'mininova.org'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://www.mininova.org/today'</span>]</span><br><span class="line">    rules = [<span class="function"><span class="title">Rule</span><span class="params">(SgmlLinkExtractor(allow=[<span class="string">'/tor/\d+'</span>])</span></span>),</span><br><span class="line">             <span class="function"><span class="title">Rule</span><span class="params">(SgmlLinkExtractor(allow=[<span class="string">'/abc/\d+'</span>])</span></span>, <span class="string">'parse_torrent'</span>)]</span><br><span class="line">    def <span class="function"><span class="title">parse_torrent</span><span class="params">(self, response)</span></span>:</span><br><span class="line">        x = <span class="function"><span class="title">HtmlXPathSelector</span><span class="params">(response)</span></span></span><br><span class="line">        torrent = <span class="function"><span class="title">TorrentItem</span><span class="params">()</span></span></span><br><span class="line">        torrent[<span class="string">'url'</span>] = response<span class="class">.url</span></span><br><span class="line">        torrent[<span class="string">'name'</span>] = x.<span class="function"><span class="title">select</span><span class="params">(<span class="string">"//h1/text()"</span>)</span></span>.<span class="function"><span class="title">extract</span><span class="params">()</span></span></span><br><span class="line">        torrent[<span class="string">'description'</span>] = x.<span class="function"><span class="title">select</span><span class="params">(<span class="string">"//div[@id='description']"</span>)</span></span>.<span class="function"><span class="title">extract</span><span class="params">()</span></span></span><br><span class="line">        torrent[<span class="string">'size'</span>] = x.<span class="function"><span class="title">select</span><span class="params">(<span class="string">"//div[@id='info-left']/p[2]/text()[2]"</span>)</span></span>.<span class="function"><span class="title">extract</span><span class="params">()</span></span></span><br><span class="line">        return torrent</span><br></pre></td></tr></table></figure></p>
<p>相比BaseSpider，新的类多了一个rules属性，这个属性是一个列表，它可以包含多个Rule，每个Rule描述了哪些链接需要抓取，哪些不需要。这是Rule类的文档<a href="http://doc.scrapy.org/en/latest/topics/spiders.html#scrapy.contrib.spiders.Rule" target="_blank" rel="external">http://doc.scrapy.org/en/latest/topics/spiders.html#scrapy.contrib.spiders.Rule</a><br>这些rule可以有callback，也可以没有，当没有callback的时候，scrapy简单的follow所有这些链接.<br>pipelines.py的使用<br>在pipelines.py中我们可以添加一些类来过滤掉我们不想要的item，把item保存到数据库。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.exceptions <span class="keyword">import</span> DropItem</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FilterWordsPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""A pipeline for filtering out items which contain certain words in their</span><br><span class="line">    description"""</span></span><br><span class="line">    <span class="comment"># put all words in lowercase</span></span><br><span class="line">    words_to_filter = [<span class="string">'politics'</span>, <span class="string">'religion'</span>]</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> self.words_to_filter:</span><br><span class="line">            <span class="keyword">if</span> word <span class="keyword">in</span> unicode(item[<span class="string">'description'</span>]).lower():</span><br><span class="line">                <span class="keyword">raise</span> DropItem(<span class="string">"Contains forbidden word: %s"</span> % word)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure></p>
<p>如果item不符合要求，那么就抛一个异常，这个item不会被输出到json文件中。<br>要使用pipelines，我们还需要修改settings.py<br>添加一行<br>ITEM_PIPELINES = [‘dirbot.pipelines.FilterWordsPipeline’]<br>现在执行<strong>scrapy crawl dmoz -o items.json -t json</strong>，不符合要求的item就被过滤掉了，这时在tutorial目录下会生成一个如下图所示的items.json文件</p>
<p><center><img src="http://7xiur2.com1.z0.glb.clouddn.com/0046.png" alt=""></center></p>
<h1 id="将数据保存到mysql数据库">将数据保存到mysql数据库</h1><h2 id="数据库建表语句">数据库建表语句</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator"><span class="keyword">create</span> <span class="keyword">table</span> book ( title <span class="built_in">char</span>(<span class="number">15</span>) <span class="keyword">not</span> <span class="literal">null</span>, link <span class="built_in">varchar</span>(<span class="number">50</span>) <span class="keyword">COLLATE</span> gb2312_chinese_ci <span class="keyword">DEFAULT</span> <span class="literal">NULL</span>);</span></span><br></pre></td></tr></table></figure>
<h2 id="中文乱码问题">中文乱码问题</h2><p><strong>如果出现中文乱码问题请将数据库编码格式设置成gb2312_chinese_ci</strong></p>
<h2 id="配置pipelines-py">配置pipelines.py</h2><p>添加如下代码：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> log</span><br><span class="line"><span class="keyword">from</span> twisted.enterprise <span class="keyword">import</span> adbapi</span><br><span class="line"><span class="keyword">from</span> scrapy.http <span class="keyword">import</span> Request</span><br><span class="line"><span class="keyword">from</span> scrapy.exceptions <span class="keyword">import</span> DropItem</span><br><span class="line"><span class="keyword">from</span> scrapy.contrib.pipeline.images <span class="keyword">import</span> ImagesPipeline</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> MySQLdb</span><br><span class="line"><span class="keyword">import</span> MySQLdb.cursors</span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="keyword">import</span> select</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> errno</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySQLStorePipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.dbpool = adbapi.ConnectionPool(<span class="string">'MySQLdb'</span>,</span><br><span class="line">            db = <span class="string">'test'</span>,<span class="number">8</span> <span class="comment">#数据库名称</span></span><br><span class="line">            user = <span class="string">'root'</span>, <span class="comment">#数据库用户名</span></span><br><span class="line">            passwd = <span class="string">''</span>,  <span class="comment">#数据库密码</span></span><br><span class="line">            cursorclass = MySQLdb.cursors.DictCursor,</span><br><span class="line">            charset = <span class="string">'utf8'</span>,</span><br><span class="line">            use_unicode = <span class="keyword">False</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        query = self.dbpool.runInteraction(self._conditional_insert, item)</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_conditional_insert</span><span class="params">(self, tx, item)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> item.get(<span class="string">'title'</span>):</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(len(item[<span class="string">'title'</span>])):</span><br><span class="line">                tx.execute(<span class="string">'insert into book values (%s, %s)'</span>, (item[<span class="string">'title'</span>][i], item[<span class="string">'link'</span>][i]))</span><br></pre></td></tr></table></figure></p>
<h2 id="配置setting-py">配置setting.py</h2><p>添加如下代码：<br><figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="title">ITEM_PIPELINES</span> = [<span class="string">'tutorial.pipelines.MySQLStorePipeline'</span>]</span><br></pre></td></tr></table></figure></p>
<h2 id="执行scrapy_crawl_dmoz">执行scrapy crawl dmoz</h2><p>运行效果如下</p>
<p><center><img src="http://7xiur2.com1.z0.glb.clouddn.com/0048.png" alt=""></center></p>
<h1 id="Python脚本运行出现语法错误">Python脚本运行出现语法错误</h1><p>解决方案：<br><a href="http://www.crifan.com/python_syntax_error_indentationerror/comment-page-1/" target="_blank" rel="external">http://www.crifan.com/python_syntax_error_indentationerror/comment-page-1/</a></p>
<h1 id="生成的json文件编码默认为Unicode">生成的json文件编码默认为Unicode</h1><p>如下：<br><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">[&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"\u4e3b\u9875"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"/"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"\u6587\u7ae0\u5217\u8868"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"/archives"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[]</span>, "<span class="attribute">desc</span>": <span class="value">[<span class="string">"\n \t\t\t\t\t\n\t\t\t\t\t"</span>, <span class="string">"\n\t\t\t\t\t\n\t\t\t\t\t"</span>]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"Java"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"/tags/Java/"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"\u7b97\u6cd5"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"/tags/\u7b97\u6cd5/"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"\u6570\u636e\u6316\u6398"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"/tags/\u6570\u636e\u6316\u6398/"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"\u7269\u8054\u7f51"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"/tags/\u7269\u8054\u7f51/"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"C++"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"/tags/C/"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"openHAB"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"/tags/openHAB/"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"\u4e91\u8ba1\u7b97"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"/tags/\u4e91\u8ba1\u7b97/"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"C"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"/tags/C/"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"\u79fb\u52a8\u4e92\u8054\u7f51"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"/tags/\u79fb\u52a8\u4e92\u8054\u7f51/"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"GC"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"/tags/GC/"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"\u5927\u6570\u636e"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"/tags/\u5927\u6570\u636e/"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"\u5fae\u535a"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"http://weibo.com/jiayou087"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[<span class="string">"\n            \n            \t"</span>, <span class="string">"\n            \n          "</span>]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"CSDN"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"http://blog.csdn.net/pangjiuzala"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[<span class="string">"\n            \n            \t"</span>, <span class="string">"\n            \n          "</span>]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"July 2015"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"/archives/2015/07/"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[]</span>&#125;]</span><br></pre></td></tr></table></figure></p>
<p>解决方案：</p>
<h2 id="配置pipelines-py文件">配置pipelines.py文件</h2><p>添加如下代码；<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JsonWriterPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.file = codecs.open(<span class="string">'items.json'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        line = json.dumps(dict(item)) + <span class="string">"\n"</span></span><br><span class="line">        self.file.write(line.decode(<span class="string">'unicode_escape'</span>))</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure></p>
<h2 id="配置settings-py文件">配置settings.py文件</h2><p>添加如下代码；<br><figure class="highlight actionscript"><table><tr><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;<span class="string">'tutorial.pipelines.JsonWriterPipeline'</span>&#125;</span><br></pre></td></tr></table></figure></p>
<p>转化后的数据如下：<br><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">[&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"主页"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"/"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"文章列表"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"/archives"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[]</span>, "<span class="attribute">desc</span>": <span class="value">[<span class="string">"\n \t\t\t\t\t\n\t\t\t\t\t"</span>, <span class="string">"\n\t\t\t\t\t\n\t\t\t\t\t"</span>]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"Java"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"/tags/Java/"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"算法"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"/tags/算法/"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"数据挖掘"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"/tags/数据挖掘/"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"物联网"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"/tags/物联网/"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"C++"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"/tags/C/"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"openHAB"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"/tags/openHAB/"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"云计算"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"/tags/云计算/"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"C"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"/tags/C/"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"移动互联网"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"/tags/移动互联网/"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"GC"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"/tags/GC/"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"大数据"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"/tags/大数据/"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"微博"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"http://weibo.com/jiayou087"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[<span class="string">"\n            \n            \t"</span>, <span class="string">"\n            \n          "</span>]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"CSDN"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"http://blog.csdn.net/pangjiuzala"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[<span class="string">"\n            \n            \t"</span>, <span class="string">"\n            \n          "</span>]</span>&#125;,</span><br><span class="line">&#123;"<span class="attribute">title</span>": <span class="value">[<span class="string">"July 2015"</span>]</span>, "<span class="attribute">tag</span>": <span class="value">[]</span>, "<span class="attribute">link</span>": <span class="value">[<span class="string">"/archives/2015/07/"</span>]</span>, "<span class="attribute">desc</span>": <span class="value">[]</span>&#125;]</span><br></pre></td></tr></table></figure></p>
<h1 id="使用Beautiful_Soup">使用Beautiful Soup</h1><p>详情链接：<br><a href="http://kevinkelly.blog.163.com/blog/static/21390809320133185748442/" target="_blank" rel="external">http://kevinkelly.blog.163.com/blog/static/21390809320133185748442/</a></p>
  
	</div>
		<footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/Python/">Python</a><a href="/tags/网络爬虫/">网络爬虫</a>
  </div>

</div>



	<div class="article-share" id="share">
	
	<div class="share-jiathis">
	  
<div class="jiathis_style_24x24">
	<a class="jiathis_button_tsina"></a>
	<a class="jiathis_button_weixin"></a>
	<a class="jiathis_button_renren"></a>
	<a class="jiathis_button_qzone"></a>
	<a class="jiathis_button_googleplus"></a>
	<a class="jiathis_button_douban"></a>
	<a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" >
    var jiathis_config={
    data_track_clickback:true,
    sm:"copy,renren,cqq",
    pic:"",
    summary:"",
    
  </script> 
<script type="text/javascript" src="//v3.jiathis.com/code/jia.js?uid=
" charset="utf-8"></script>      

	 </div>
	
	</div>


</footer>

   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2015/07/23/数据挖掘笔记/" title="数据挖掘笔记">
  <strong>上一篇：</strong><br/>
  <span>
  数据挖掘笔记</span>
</a>
</div>


<div class="next">
<a href="/2015/07/21/大数据，云计算，物联网和移动互联网关系图解/"  title="大数据，云计算，物联网和移动互联网关系图解">
 <strong>下一篇：</strong><br/> 
 <span>大数据，云计算，物联网和移动互联网关系图解
</span>
</a>
</div>

</nav>

	
<section id="comments" class="comment">
	<div class="ds-thread" data-thread-key="2015/07/22/Scrapy安装及使用/" data-title="Scrapy安装及使用" data-url="http://pangjiuzala.github.io/2015/07/22/Scrapy安装及使用/"></div>
</section>


</div>  
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">文章目录</strong>
 
 <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Scrapy简介"><span class="toc-number">1.</span> <span class="toc-text">Scrapy简介</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#安装Python2-7"><span class="toc-number">2.</span> <span class="toc-text">安装Python2.7</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#安装python"><span class="toc-number">2.1.</span> <span class="toc-text">安装python</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#添加环境变量"><span class="toc-number">2.2.</span> <span class="toc-text">添加环境变量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#验证环境变量"><span class="toc-number">2.3.</span> <span class="toc-text">验证环境变量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#验证Python"><span class="toc-number">2.4.</span> <span class="toc-text">验证Python</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#安装Scrapy"><span class="toc-number">3.</span> <span class="toc-text">安装Scrapy</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#生成项目"><span class="toc-number">4.</span> <span class="toc-text">生成项目</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#将数据保存到mysql数据库"><span class="toc-number">5.</span> <span class="toc-text">将数据保存到mysql数据库</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#数据库建表语句"><span class="toc-number">5.1.</span> <span class="toc-text">数据库建表语句</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#中文乱码问题"><span class="toc-number">5.2.</span> <span class="toc-text">中文乱码问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#配置pipelines-py"><span class="toc-number">5.3.</span> <span class="toc-text">配置pipelines.py</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#配置setting-py"><span class="toc-number">5.4.</span> <span class="toc-text">配置setting.py</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#执行scrapy_crawl_dmoz"><span class="toc-number">5.5.</span> <span class="toc-text">执行scrapy crawl dmoz</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Python脚本运行出现语法错误"><span class="toc-number">6.</span> <span class="toc-text">Python脚本运行出现语法错误</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#生成的json文件编码默认为Unicode"><span class="toc-number">7.</span> <span class="toc-text">生成的json文件编码默认为Unicode</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#配置pipelines-py文件"><span class="toc-number">7.1.</span> <span class="toc-text">配置pipelines.py文件</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#配置settings-py文件"><span class="toc-number">7.2.</span> <span class="toc-text">配置settings.py文件</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#使用Beautiful_Soup"><span class="toc-number">8.</span> <span class="toc-text">使用Beautiful Soup</span></a></li></ol>
 
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  <div class="weiboshow">
  <p class="asidetitle">新浪微博</p>
    <iframe width="100%" height="119" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=119&fansRow=2&ptype=1&speed=0&skin=9&isTitle=1&noborder=1&isWeibo=0&isFans=0&uid=2129798793&verifier=c0951e84&dpc=1"></iframe>
</div>


  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/Java/" title="Java">Java<sup>9</sup></a></li>
			
		
			
				<li><a href="/tags/算法/" title="算法">算法<sup>5</sup></a></li>
			
		
			
				<li><a href="/tags/数据挖掘/" title="数据挖掘">数据挖掘<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/移动互联网/" title="移动互联网">移动互联网<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/Android/" title="Android">Android<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/云平台/" title="云平台">云平台<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/物联网/" title="物联网">物联网<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/openHAB/" title="openHAB">openHAB<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/云计算/" title="云计算">云计算<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/C/" title="C++">C++<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/C/" title="C">C<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/设计模式/" title="设计模式">设计模式<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/大数据/" title="大数据">大数据<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Python/" title="Python">Python<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/网络爬虫/" title="网络爬虫">网络爬虫<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/操作系统/" title="操作系统">操作系统<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/OpenStack/" title="OpenStack">OpenStack<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/智慧医疗/" title="智慧医疗">智慧医疗<sup>1</sup></a></li>
			
		
		</ul>
</div>


  <div class="rsspart">
	<a href="https://github.com/search?q=pangjiuzala&amp;type=Users" target="_blank" title="关注刘兴的github">关注</a>
</div>

  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
          <li>
            
            	<a href="http://blog.csdn.net/pangjiuzala" target="_blank" title="刘兴的CSDN博客">CSDN</a>
            
          </li>
        
    </ul>
</div>

  

  

  


  
  <div class="archiveslist">
    <p class="asidetitle"><a href="/archives">归档</a></p>
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/07/">July 2015</a><span class="archive-list-count">23</span></li></ul>
  </div>


</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello,I&#39;m from ZjuCs! <br/>
			The more you diligent, the more you lucky!</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		
		
		
		
		
		
		
		
		
	</div>
			
		

		<p class="copyright">
		Copyright@ 2015 Liuxing All rights reserved.
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  c.click(function(){
    ta.css('display', 'block').addClass('fadeIn');
  });
  o.click(function(){
    ta.css('display', 'none');
  });
  $(window).scroll(function(){
    ta.css("top",Math.max(140,320-$(this).scrollTop()));
  });
});
</script>




<script type="text/javascript">
  var duoshuoQuery = {short_name:"pangjiuzala"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
    || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
</script> 







<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->

<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'null', 'null');  
ga('send', 'pageview');
</script>



<script type="text/javascript">
var _bdhmProtocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cscript src='" + _bdhmProtocol + "hm.baidu.com/h.js%3Ffeafc504b70a541dd3845d467335f367' type='text/javascript'%3E%3C/script%3E"));
</script>



<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_null'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s23.cnzz.com/z_stat.php%3Fid%3Dnull' type='text/javascript'%3E%3C/script%3E"));</script>

<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<script>
var option = {
  engineKey: '4ac092ad8d749fdc6293'
};
(function(w,d,t,u,n,s,e){
  s = d.createElement(t);
  s.src = u;
  s.async = 1;
  w[n] = function(r){
    w[n].opts = r;
  };
  e = d.getElementsByTagName(t)[0];
  e.parentNode.insertBefore(s, e);
})(window,document,'script','//tinysou-cdn.b0.upaiyun.com/ts.js','_ts');
_ts(option);
</script>

<!-- Tiny_search End -->

  </body>
</html>
