
 <!DOCTYPE HTML>
<html >
<head>
  <meta charset="UTF-8">
  
    <title>数据挖掘算法 | 刘兴的博客</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="刘兴">
    

    
    <meta name="description" content="本文总结了数据挖掘以及机器学习中常见算法如神经网络算法、随机森林算法以及决策树等，希望能对数据挖掘爱好者有一定帮助。">
<meta property="og:type" content="article">
<meta property="og:title" content="数据挖掘算法">
<meta property="og:url" content="http://pangjiuzala.github.io/2015/07/28/数据挖掘算法/index.html">
<meta property="og:site_name" content="刘兴的博客">
<meta property="og:description" content="本文总结了数据挖掘以及机器学习中常见算法如神经网络算法、随机森林算法以及决策树等，希望能对数据挖掘爱好者有一定帮助。">
<meta property="og:image" content="http://7xiur2.com1.z0.glb.clouddn.com/%E5%9B%BE%E7%89%871.jpg">
<meta property="og:image" content="http://7xiur2.com1.z0.glb.clouddn.com/%E5%9B%BE%E7%89%872.jpg">
<meta property="og:updated_time" content="2015-07-28T02:51:40.884Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="数据挖掘算法">
<meta name="twitter:description" content="本文总结了数据挖掘以及机器学习中常见算法如神经网络算法、随机森林算法以及决策树等，希望能对数据挖掘爱好者有一定帮助。">

    
    <link rel="alternative" href="https://github.com/search?q=pangjiuzala&type=Users" title="刘兴的博客" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css" type="text/css">
</head>

  <body>
    <header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.png" alt="刘兴的博客" title="刘兴的博客"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="刘兴的博客">刘兴的博客</a></h1>
				<h2 class="blog-motto"></h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">主页</a></li>
					
						<li><a href="/archives">文章列表</a></li>
					
					<li>
 					
					<form class="search" action="/search/index.html" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" autocomplete="off" name="q" maxlength="20" placeholder="搜索" />
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
  
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2015/07/28/数据挖掘算法/" title="数据挖掘算法" itemprop="url">数据挖掘算法</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="刘兴" target="_blank" itemprop="author">刘兴</a>
		
  <p class="article-time">
    <time datetime="2015-07-28T02:43:09.000Z" itemprop="datePublished"> 发表于 2015-07-28</time>
    
  </p>
</header>
	<div class="article-content">
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">文章目录</strong>
		
			<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#神经网络算法"><span class="toc-number">1.</span> <span class="toc-text">神经网络算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#简介"><span class="toc-number">1.1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#神经网络"><span class="toc-number">1.2.</span> <span class="toc-text">神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#人工神经网络"><span class="toc-number">1.3.</span> <span class="toc-text">人工神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#BP神经网络模型"><span class="toc-number">1.4.</span> <span class="toc-text">BP神经网络模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#传统的BP算法简述"><span class="toc-number">1.4.1.</span> <span class="toc-text">传统的BP算法简述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#改进的BP网络算法"><span class="toc-number">1.4.2.</span> <span class="toc-text">改进的BP网络算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#计算机运算实例"><span class="toc-number">1.4.3.</span> <span class="toc-text">计算机运算实例</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#随机森林"><span class="toc-number">2.</span> <span class="toc-text">随机森林</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#随机森林-1"><span class="toc-number">2.1.</span> <span class="toc-text">随机森林</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#训练算法"><span class="toc-number">2.2.</span> <span class="toc-text">训练算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#洞察"><span class="toc-number">2.3.</span> <span class="toc-text">洞察</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#结论"><span class="toc-number">2.4.</span> <span class="toc-text">结论</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#决策树"><span class="toc-number">3.</span> <span class="toc-text">决策树</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#简介-1"><span class="toc-number">3.1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#组成"><span class="toc-number">3.2.</span> <span class="toc-text">组成</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#画法"><span class="toc-number">3.3.</span> <span class="toc-text">画法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#决策树的剪枝"><span class="toc-number">3.4.</span> <span class="toc-text">决策树的剪枝</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#决策树的应用"><span class="toc-number">3.5.</span> <span class="toc-text">决策树的应用</span></a></li></ol></li></ol>
		
		</div>
		
		<p>本文总结了数据挖掘以及机器学习中常见算法如神经网络算法、随机森林算法以及决策树等，希望能对数据挖掘爱好者有一定帮助。<br><a id="more"></a></p>
<h1 id="神经网络算法">神经网络算法</h1><h2 id="简介">简介</h2><p>逻辑性的思维是指根据逻辑规则进行推理的过程；它先将信息化成概念，并用符号表示，然后，根据符号运算按串行模式进行逻辑推理；这一过程可以写成串行的指令，让计算机执行。然而，直观性的思维是将分布式存储的信息综合起来，结果是忽然间产生想法或解决问题的办法。这种思维方式的根本之点在于以下两点：1.信息是通过神经元上的兴奋模式分布储在网络上；1.信息处理是通过神经元之间同时相互作用的动态过程来完成的。</p>
<h2 id="神经网络">神经网络</h2><p>思维学普遍认为，人类大脑的思维分为抽象（逻辑）思维、形象（直观）思维和灵感（顿悟）思维三种基本方式。<br>人工神经网络就是模拟人思维的第二种方式。这是一个非线性动力学系统，其特色在于信息的分布式存储和并行协同处理。虽然单个神经元的结构极其简单，功能有限，但大量神经元构成的网络系统所能实现的行为却是极其丰富多彩的。<br>神经网络的研究内容相当广泛，反映了多学科交叉技术领域的特点。主要的研究工作集中在以下几个方面：<br>（1）生物原型研究。从生理学、心理学、解剖学、脑科学、病理学等生物科学方面研究神经细胞、神经网络、神经系统的生物原型结构及其功能机理。<br>（2）建立理论模型。根据生物原型的研究，建立神经元、神经网络的理论模型。其中包括概念模型、知识模型、物理化学模型、数学模型等。<br>（3）网络模型与算法研究。在理论模型研究的基础上构作具体的神经网络模型，以实现计算机模拟或准备制作硬件，包括网络学习算法的研究。这方面的工作也称为技术模型研究。<br>（4）人工神经网络应用系统。在网络模型与算法研究的基础上，利用人工神经网络组成实际的应用系统，例如，完成某种信号处理或模式识别的功能、构造专家系统、制成机器人等等。<br>纵观当代新兴科学技术的发展历史，人类在征服宇宙空间、基本粒子，生命起源等科学技术领域的进程中历经了崎岖不平的道路。我们也会看到，探索人脑功能和神经网络的研究将伴随着重重困难的克服而日新月异。</p>
<h2 id="人工神经网络">人工神经网络</h2><p>人工神经网络（Artificial Neural Networks，ANN）系统是 20 世纪 40 年代后出现的。它是由众多的神经元可调的连接权值连接而成，具有大规模并行处理、分布式信 息存储、良好的自组织自学习能力等特点。BP（Back Propagation）算法又称为误差 反向传播算法，是人工神经网络中的一种监督式的学习算法。BP 神经网络算法在理 论上可以逼近任意函数，基本的结构由非线性变化单元组成，具有很强的非线性映射能力。而且网络的中间层数、各层的处理单元数及网络的学习系数等参数可根据具体情况设定，灵活性很大，在优化、信号处理与模式识别、智能控制、故障诊断等许 多领域都有着广泛的应用前景。<br><strong>工作原理</strong><br>    人工神经网络是由大量的简单基本元件——神经元相互联接而成的自适应非线性动态系统。每个神经元的结构和功能比较简单，但大量神经元组合产生的系统行为却非常复杂。<br>人工神经网络反映了人脑功能的若干基本特性，但并非生物系统的逼真描述，只是某种模仿、简化和抽象。<br>与数字计算机比较，人工神经网络在构成原理和功能特点等方面更加接近人脑，它不是按给定的程序一步一步地执行运算，而是能够自身适应环境、总结规律、完成某种运算、识别或过程控制。<br>人工神经网络首先要以一定的学习准则进行学习，然后才能工作。现以人工神经网络对于写“A”、“B”两个字母的识别为例进行说明，规定当“A”输入网络时，应该输出“1”，而当输入为“B”时，输出为“0”。<br>所以网络学习的准则应该是：如果网络作出错误的的判决，则通过网络的学习，应使得网络减少下次犯同样错误的可能性。首先，给网络的各连接权值赋予(0，1)区间内的随机值，将“A”所对应的图象模式输入给网络，网络将输入模式加权求和、与门限比较、再进行非线性运算，得到网络的输出。在此情况下，网络输出为“1”和“0”的概率各为50%，也就是说是完全随机的。这时如果输出为“1”(结果正确)，则使连接权值增大，以便使网络再次遇到“A”模式输入时，仍然能作出正确的判断。<br>如果输出为“0”(即结果错误)，则把网络连接权值朝着减小综合输入加权值的方向调整，其目的在于使网络下次再遇到“A”模式输入时，减小犯同样错误的可能性。如此操作调整，当给网络轮番输入若干个手写字母“A”、“B”后，经过网络按以上学习方法进行若干次学习后，网络判断的正确率将大大提高。这说明网络对这两个模式的学习已经获得了成功，它已将这两个模式分布地记忆在网络的各个连接权值上。当网络再次遇到其中任何一个模式时，能够作出迅速、准确的判断和识别。一般说来，网络中所含的神经元个数越多，则它能记忆、识别的模式也就越多。<br><strong>特点</strong><br>（1）普通计算机的功能取决于程序中给出的知识和能力。显然，对于智能活动要通过总结编制程序将十分困难。<br>人工神经网络也具有初步的自适应与自组织能力。在学习或训练过程中改变突触权重值，以适应周围环境的要求。同一网络因学习方式及内容不同可具有不同的功能。人工神经网络是一个具有学习能力的系统，可以发展知识，以致超过设计者原有的知识水平。通常，它的学习训练方式可分为两种，一种是有监督或称有导师的学习，这时利用给定的样本标准进行分类或模仿；另一种是无监督学习或称无为导师学习，这时，只规定学习方式或某些规则，则具体的学习内容随系统所处环境 （即输入信号情况）而异，系统可以自动发现环境特征和规律性，具有更近似人脑的功能。<br>（2）泛化能力<br>泛化能力指对没有训练过的样本，有很好的预测能力和控制能力。特别是，当存在一些有噪声的样本，网络具备很好的预测能力。<br>(3)非线性映射能力<br>当对系统对于设计人员来说，很透彻或者很清楚时，则一般利用数值分析，偏微分方程等数学工具建立精确的数学模型，但当对系统很复杂，或者系统未知，系统信息量很少时，建立精确的数学模型很困难时，神经网络的非线性映射能力则表现出优势，因为它不需要对系统进行透彻的了解，但是同时能达到输入与输出的映射关系，这就大大简化设计的难度。<br>(4)高度并行性<br>并行性具有一定的争议性。承认具有并行性理由：神经网络是根据人的大脑而抽象出来的数学模型，由于人可以同时做一些事，所以从功能的模拟角度上看，神经网络也应具备很强的并行性。<br>下面将人工神经网络与通用的计算机工作特点来对比一下：<br>若从速度的角度出发，人脑神经元之间传递信息的速度要远低于计算机，前者为毫秒量级，而后者的频率往往可达几百兆赫。但是，由于人脑是一个大规模并行与串行组合处理系统，因而，在许多问题上可以作出快速判断、决策和处理，其速度则远高于串行结构的普通计算机。人工神经网络的基本结构模仿人脑，具有并行处理特征，可以大大提高工作速度。<br>人脑存贮信息的特点为利用突触效能的变化来调整存贮内容，也即信息存贮在神经元之间连接强度的分布上，存贮区与计算机区合为一体。虽然人脑每日有大量神经细胞死亡 （平均每小时约一千个），但不影响大脑的正常思维活动。<br>普通计算机是具有相互独立的存贮器和运算器，知识存贮与数据运算互不相关，只有通过人编出的程序使之沟通，这种沟通不能超越程序编制者的预想。元器件的局部损坏及程序中的微小错误都可能引起严重的失常。</p>
<h2 id="BP神经网络模型">BP神经网络模型</h2><p>BP网络能学习和存贮大量的输入-输出模式映射关系，而无需事前揭示描述这种映射关系的数学方程。它的学习规则是使用最速下降法，通过反向传播来不断调整网络的权值和阈值，使网络的误差平方和最小。BP神经网络模型拓扑结构包括输入层（input）、隐层(hide layer)和输出层(output layer)。BP神经网络算法是在BP神经网络现有算法的基础上提出的，是通过任意选定一组权值，将给定的目标输出直接作为线性方程的代数和来建立线性方程组，解得待求权，不存在传统方法的局部极小及收敛速度慢的问题，且更易理解。</p>
<h3 id="传统的BP算法简述">传统的BP算法简述</h3><p>BP算法是一种有监督式的学习算法，其主要思想是：输入学习样本，使用反向传播算法对网络的权值和偏差进行反复的调整训练，使输出的向量与期望向量尽可能地接近，当网络输出层的误差平方和小于指定的误差时训练完成，保存网络的权值和偏差。具体步骤如下：<br>（1）初始化，随机给定各连接权[w],[v]及阀值θi，rt。<br>（2）由给定的输入输出模式对计算隐层、输出层各单元输出<br>bj=f（■wijai-θj） ct=f（■vjtbj－rt）<br>式中：bj为隐层第j个神经元实际输出；ct为输出层第t个神经元的实际输出；wij为输入层至隐层的连接权；vjt为隐层至输出层的连接权。<br>dtk=（ytk－ct）ct（1－ct） ejk=[■dtvjt] bj（1－bj）<br>式中：dtk为输出层的校正误差；ejk为隐层的校正误差。<br>（3）计算新的连接权及阀值，计算公式如下：<br>vjt（n+1）=vjt（n）+?琢dtkbj wij（n+1）=wij（n）+?茁ejkaik<br>rt（n+1）=rt（n）+?琢dtk θj（n+1）=θj（n）+?茁ejk<br>式中：?琢，?茁为学习系数（0&lt;?琢&lt;1，0&lt;?茁&lt;1）。<br>（4）选取下一个输入模式对返回第2步反复训练直到网络设输出误差达到要求结束训练。<br>传统的BP算法，实质上是把一组样本输入/输出问题转化为一个非线性优化问题，并通过负梯度下降算法，利用迭代运算求解权值问题的一种学习方法，但其收敛速度慢且容易陷入局部极小，为此提出了一种新的算法，即高斯消元法。</p>
<h3 id="改进的BP网络算法">改进的BP网络算法</h3><p>改进算法概述<br>此前有人提出：任意选定一组自由权，通过对传递函数建立线性方程组，解得待求权。本文在此基础上将给定的目标输出直接作为线性方程等式代数和来建立线性方程组，不再通过对传递函数求逆来计算神经元的净输出，简化了运算步骤。没有采用误差反馈原理，因此用此法训练出来的神经网络结果与传统算法是等效的。其基本思想是：由所给的输入、输出模式对通过作用于神经网络来建立线性方程组，运用高斯消元法解线性方程组来求得未知权值，而未采用传统BP网络的非线性函数误差反馈寻优的思想。<br><strong>改进算法的具体步骤</strong><br>对给定的样本模式对，随机选定一组自由权，作为输出层和隐含层之间固定权值，通过传递函数计算隐层的实际输出，再将输出层与隐层间的权值作为待求量，直接将目标输出作为等式的右边建立方程组来求解。<br>现定义如下符号（见图1）：x （p）输入层的输入矢量；y （p）输入层输入为x （p）时输出层的实际输出矢量；t （p）目标输出矢量；n，m，r分别为输入层、隐层和输出层神经元个数；W为隐层与输入层间的权矩阵；V为输出层与隐层间的权矩阵。具体步骤如下：<br>（1）随机给定隐层和输入层间神经元的初始权值wij。<br>（2）由给定的样本输入xi（p）计算出隐层的实际输出aj（p）。为方便起见将图1网络中的阀值写入连接权中去，令：隐层阀值θj=wnj，x（n）=－1，则：<br>aj（p）=f（■wijxi（p）） （j=1，2…m－1）。<br>（3）计算输出层与隐层间的权值vjr。以输出层的第r个神经元为对象，由给定的输出目标值tr（p）作为等式的多项式值建立方程，用线性方程组表示为：<br>a0（1）v1r+a1（1）v2r+…+am（1）vmr=tr（1）a0（2）v1r+a1（2）v2r+…+am（2）vmr=tr（2） ……a0（p）v1r+a1（p）v2r+…+am（p）vmr=tr（p） 简写为： Av=T<br>为了使该方程组有唯一解，方程矩阵A为非奇异矩阵，其秩等于其增广矩阵的秩，即：r（A）=r（A┊B），且方程的个数等于未知数的个数，故取m=p，此时方程组的唯一解为： Vr=[v0r，v2r，…vmr]（r=0，1，2…m－1）<br>（4）重复第三步就可以求出输出层m个神经元的权值，以求的输出层的权矩阵加上随机固定的隐层与输入层的权值就等于神经网络最后训练的权矩阵。</p>
<h3 id="计算机运算实例">计算机运算实例</h3><p>现以神经网络最简单的XOR问题用VC编程运算进行比较（取神经网络结构为2－4－1型），传统算法和改进BP算法的误差（取动量因子α=0．001 5，步长η=1．653）</p>
<h1 id="随机森林">随机森林</h1><h2 id="随机森林-1">随机森林</h2><p>回到shell selling，我们测试了几种算法，然后选定能给以我们最好的性能的算法：随机森林。<br>随机森林是Leo Breiman 和 Adele Cutler开发的一种基于树形结构的集成方法，由Breiman于2001年在机器学习期刊的评议文章中首次提出[1]。随机森林在训练数据的随机子集上训练许多决策树，然后使用单个树的预测均值作为最终的预测。随机子集是从原始的训练数据抽样，通过在记录级有放回抽样（bootstrap）和在特征级随机二次抽样得到。<br>我们尝试的算法的召回率，随机森林提供了最佳的精度，紧随其后的是神经网络和另外一种集成方法AdaBoost。相比于其他算法，随机森林针对我们碰到的各类欺诈数据有许多的优势：<br>(1)基于集成方法的树可以同时很好地处理非线性和非单调性，这在欺诈信号中相当普遍。相比之下，神经网络对非线性处理地相当不错，但同时受到非单调性的羁绊，而逻辑回归都无法处理。对于使用后两种方法来处理的非线性和/或非单调性，我们需要广泛的和适当的特征转换。<br>(2)随机森林需要最小的特征预备和特征转换，它不需要神经网络和逻辑回归要求的标准化输入变量，也不需要聚类和风险评级转换为非单调变量。<br>(3)随机森林相比其他算法拥有最好的开箱即用的性能。另一个基于树的方法，梯度提升决策树（GBT），可以达到类似的性能，但需要更多的参数调优。<br>(4)随机森林输出特征的重要性体现在作为模型训练的副产品，这对于特征选择是非常有用的[2]。<br>(5)随机森林与其他算法相比具有更好的过拟合（overfitting）容错性，并且处理大量的变量也不会有太多的过拟合[1]，因为过拟合可以通过更多的决策树来削弱。此外，变量的选择和减少也不像其他算法那么重要。<br>如图1.1，下图是随机森林与其竞争对手的对比情况:<br><img src="http://7xiur2.com1.z0.glb.clouddn.com/%E5%9B%BE%E7%89%871.jpg" alt=""><br>图1.1随机森林与其竞争对手的对比情况</p>
<h2 id="训练算法">训练算法</h2><p>我们的机器学习流程遵循一个标准程序，包括数据抽取、数据清洗、特征推导、特征工程和转换、特征选择、模型训练和模型性能评价，如图1.2</p>
<p>图1.2 机器学习流程<br><img src="http://7xiur2.com1.z0.glb.clouddn.com/%E5%9B%BE%E7%89%872.jpg" alt=""></p>
<h2 id="洞察">洞察</h2><p>经过大量的训练，我们的随机森林算法对于shell selling的识别已经成为现实，并且积极地阻止欺诈。当然我们还需要大量的工作去选择、训练和部署该算法，但是它已经使得我们的风险流程更加健壮，且有能力使用更少的人工来检查抓住更多的欺诈。在同一欺诈召回率，这一模型的精度是不断调整和优化规则的2 - 3倍。<br>使用这种算法，除了得到明显的好处以外，我们对于数据和建模过程中使用的方法也有了更多的理解：<br>(1)通过特征选择的过程，我们发现对这种欺诈行为最有预测力的特征是速度型的变量。这些包括用户的交易量、设备、真正的IP和信用卡。我们还发现，设备ID、银行账户和信用卡等账户相关特性都是很有用的，如多个账户登录到一个设备，以及多重提款到一个银行账户。<br>(2)风险等级的分类变量，如电子邮件域，应用程序ID、用户的国家，以及一天中的时间风险评级，也证明了高度预测性。<br>(3)数字足迹诸如浏览器语言、操作系统字体、屏幕分辨率、用户代理、flash版本等对于反欺诈是有点用的。稍微有更多预测性的是在人们隐藏他们的数字足迹过程当中，例如VPN隧道或虚拟机和TOR的使用。<br>(4)我们还发现模型性能迅速恶化。这真的不是一个惊喜——骗子不断改变他们的方法来避免检测，所以即使是最好的模型，如果不改变也终将过时。但是我们非常惊讶这发生的速度有多快。对shell selling而言，在模型训练后仅仅第一个月精度便下降一半。因此, 经常刷新模型来保持高检测精度对于欺诈检测的成功是至关重要的。<br>(5)不幸的是，频繁刷新暴露出他们自己的问题。虽然刷新模型尽可能经常是理想的，但是在使用最近的事务数据来训练模型时必须格外小心。欺诈标签可以需要一个月成熟，所以事实上使用最近的数据也会污染模型。和我们最初的假设不同，利用最新数据在线学习并不会总能得到最好的结果。<br>(6)随机森林是一个生产高性能模型的优异的机器学习算法，然而，它通常被用来作为一个黑盒方法。这是一个问题，因为我们并不是试图要完全削减人类的全部过程，而且很有可能无法做到即使我们愿意。人类分析师总是希望得到原因代码，告诉他们为什么事情被标记之后来引导他们的案件审查。但随机森林，就其本身而言，不能随时提供原因代码。解释模型数据是困难的，而且还可能涉及挖掘“森林”的结构，这可以显著提高评分的时间。实际上，为了应对这个问题，WePay的数据科学团队发明了一种新的私有方法可以从随机森林算生成原因代码，我们为这种方法申请了临时专利。</p>
<h2 id="结论">结论</h2><p>风险管理技术是WePay的核心。风险管理不仅仅是技术，它还体现了人类和技术无缝合作的伙伴关系。它在很大程度上仍然是人类不得不思考的方式，骗子可以攻击一个支付系统，编写规则来阻止它们，而且还是一个经验丰富的专业人员，当它下跌到 “明显欺诈”和“显然合法” 之间的灰色地带时，它必须像经常处理的那样，做出判断是否阻止交易。<br>这就是为什么我们如此兴奋于机器学习和人工智能。我们并非试图取代人类，只是希望机器智能更加聪明更好地工作，而我们可以集中人类智慧关注其他的大难题。</p>
<h1 id="决策树">决策树</h1><h2 id="简介-1">简介</h2><p>项目风险，判断其可行性的决策分析方法，是直观运用概率分析的一种图解法。由于这种决策分支画成图形很像一棵树的枝干，故称决策树。在机器学习中，决策树是一个预测模型，他代表的是对象属性与对象值之间的一种映射关系。Entropy = 系统的凌乱程度，使用算法ID3, C4.5和C5.0生成树算法使用熵。这一度量是基于信息学理论中熵的概念。<br>决策树是一种树形结构，其中每个内部节点表示一个属性上的测试，每个分支代表一个测试输出，每个叶节点代表一种类别。<br>分类树（决策树）是一种十分常用的分类方法。他是一种监管学习，所谓监管学习就是给定一堆样本，每个样本都有一组属性和一个类别，这些类别是事先确定的，那么通过学习得到一个分类器，这个分类器能够对新出现的对象给出正确的分类。这样的机器学习就被称之为监督学习。</p>
<h2 id="组成">组成</h2><p>□——决策点，是对几种可能方案的选择，即最后选择的最佳方案。如果决策属于多级决策，则决策树的中间可以有多个决策点，以决策树根部的决策点为最终决策方案。<br>○——状态节点，代表备选方案的经济效果（期望值），通过各状态节点的经济效果的对比，按照一定的决策标准就可以选出最佳方案。由状态节点引出的分支称为概率枝，概率枝的数目表示可能出现的自然状态数目每个分枝上要注明该状态出现的概率。<br>△——结果节点，将每个方案在各种自然状态下取得的损益值标注于结果节点的右端。</p>
<h2 id="画法">画法</h2><p>机器学习中，决策树是一个预测模型；他代表的是对象属性与对象值之间的一种映射关系。树中每个节点表示某个对象，而每个分叉路径则代表的某个可能的属性值，而每个叶结点则对应从根节点到该叶节点所经历的路径所表示的对象的值。决策树仅有单一输出，若欲有复数输出，可以建立独立的决策树以处理不同输出。数据挖掘中决策树是一种经常要用到的技术，可以用于分析数据，同样也可以用来作预测。<br>从数据产生决策树的机器学习技术叫做决策树学习, 通俗说就是决策树。<br>一个决策树包含三种类型的节点：<br>决策节点：通常用矩形框来表示<br>机会节点：通常用圆圈来表示<br>终结点：通常用三角形来表示<br>决策树学习也是资料探勘中一个普通的方法。在这里，每个决策树都表述了一种树型结构，它由它的分支来对该类型的对象依靠属性进行分类。每个决策树可以依靠对源数据库的分割进行数据测试。这个过程可以递归式的对树进行修剪。 当不能再进行分割或一个单独的类可以被应用于某一分支时，递归过程就完成了。另外，随机森林分类器将许多决策树结合起来以提升分类的正确率。<br>决策树同时也可以依靠计算条件概率来构造。<br>决策树如果依靠数学的计算方法可以取得更加理想的效果。 数据库已如下所示：</p>
<p>　　(x, y) = (x1, x2, x3…, xk, y)<br>相关的变量 Y 表示我们尝试去理解，分类或者更一般化的结果。 其他的变量x1, x2, x3 等则是帮助我们达到目的的变量。</p>
<h2 id="决策树的剪枝">决策树的剪枝</h2><p>剪枝是决策树停止分支的方法之一，剪枝有分预先剪枝和后剪枝两种。预先剪枝是在树的生长过程中设定一个指标，当达到该指标时就停止生长，这样做容易产生“视界局限”，就是一旦停止分支，使得节点N成为叶节点，就断绝了其后继节点进行“好”的分支操作的任何可能性。不严格的说这些已停止的分支会误导学习算法，导致产生的树不纯度降差最大的地方过分靠近根节点。后剪枝中树首先要充分生长，直到叶节点都有最小的不纯度值为止，因而可以克服“视界局限”。然后对所有相邻的成对叶节点考虑是否消去它们，如果消去能引起令人满意的不纯度增长，那么执行消去，并令它们的公共父节点成为新的叶节点。这种“合并”叶节点的做法和节点分支的过程恰好相反，经过剪枝后叶节点常常会分布在很宽的层次上，树也变得非平衡。后剪枝技术的优点是克服了“视界局限”效应，而且无需保留部分样本用于交叉验证，所以可以充分利用全部训练集的信息。但后剪枝的计算量代价比预剪枝方法大得多，特别是在大样本集中，不过对于小样本的情况，后剪枝方法还是优于预剪枝方法的。</p>
<h2 id="决策树的应用">决策树的应用</h2><p><a href="%E5%86%B3%E7%AD%96%E6%A0%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86%20-%20bourneli%20-%20%E5%8D%9A%E5%AE%A2%E5%9B%AD">决策树学习笔记整理</a></p>
  
	</div>
		<footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/算法/">算法</a>
  </div>

</div>



	<div class="article-share" id="share">
	
	<div class="share-jiathis">
	  
<div class="jiathis_style_24x24">
	<a class="jiathis_button_tsina"></a>
	<a class="jiathis_button_weixin"></a>
	<a class="jiathis_button_renren"></a>
	<a class="jiathis_button_qzone"></a>
	<a class="jiathis_button_googleplus"></a>
	<a class="jiathis_button_douban"></a>
	<a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" >
    var jiathis_config={
    data_track_clickback:true,
    sm:"copy,renren,cqq",
    pic:"",
    summary:"",
    
  </script> 
<script type="text/javascript" src="//v3.jiathis.com/code/jia.js?uid=
" charset="utf-8"></script>      

	 </div>
	
	</div>


</footer>

   	       
	</article>
	
<nav class="article-nav clearfix">
 

<div class="next">
<a href="/2015/07/27/深入JVM/"  title="深入JVM">
 <strong>下一篇：</strong><br/> 
 <span>深入JVM
</span>
</a>
</div>

</nav>

	
<section id="comments" class="comment">
	<div class="ds-thread" data-thread-key="2015/07/28/数据挖掘算法/" data-title="数据挖掘算法" data-url="http://pangjiuzala.github.io/2015/07/28/数据挖掘算法/"></div>
</section>


</div>  
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">文章目录</strong>
 
 <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#神经网络算法"><span class="toc-number">1.</span> <span class="toc-text">神经网络算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#简介"><span class="toc-number">1.1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#神经网络"><span class="toc-number">1.2.</span> <span class="toc-text">神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#人工神经网络"><span class="toc-number">1.3.</span> <span class="toc-text">人工神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#BP神经网络模型"><span class="toc-number">1.4.</span> <span class="toc-text">BP神经网络模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#传统的BP算法简述"><span class="toc-number">1.4.1.</span> <span class="toc-text">传统的BP算法简述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#改进的BP网络算法"><span class="toc-number">1.4.2.</span> <span class="toc-text">改进的BP网络算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#计算机运算实例"><span class="toc-number">1.4.3.</span> <span class="toc-text">计算机运算实例</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#随机森林"><span class="toc-number">2.</span> <span class="toc-text">随机森林</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#随机森林-1"><span class="toc-number">2.1.</span> <span class="toc-text">随机森林</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#训练算法"><span class="toc-number">2.2.</span> <span class="toc-text">训练算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#洞察"><span class="toc-number">2.3.</span> <span class="toc-text">洞察</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#结论"><span class="toc-number">2.4.</span> <span class="toc-text">结论</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#决策树"><span class="toc-number">3.</span> <span class="toc-text">决策树</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#简介-1"><span class="toc-number">3.1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#组成"><span class="toc-number">3.2.</span> <span class="toc-text">组成</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#画法"><span class="toc-number">3.3.</span> <span class="toc-text">画法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#决策树的剪枝"><span class="toc-number">3.4.</span> <span class="toc-text">决策树的剪枝</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#决策树的应用"><span class="toc-number">3.5.</span> <span class="toc-text">决策树的应用</span></a></li></ol></li></ol>
 
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  

  

  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/Java/" title="Java">Java<sup>8</sup></a></li>
			
		
			
				<li><a href="/tags/算法/" title="算法">算法<sup>5</sup></a></li>
			
		
			
				<li><a href="/tags/移动互联网/" title="移动互联网">移动互联网<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/云平台/" title="云平台">云平台<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/Android/" title="Android">Android<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/数据挖掘/" title="数据挖掘">数据挖掘<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/物联网/" title="物联网">物联网<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/openHAB/" title="openHAB">openHAB<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/云计算/" title="云计算">云计算<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/C/" title="C++">C++<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/C/" title="C">C<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/GC/" title="GC">GC<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/设计模式/" title="设计模式">设计模式<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/大数据/" title="大数据">大数据<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Python/" title="Python">Python<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/网络爬虫/" title="网络爬虫">网络爬虫<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/操作系统/" title="操作系统">操作系统<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/OpenStack/" title="OpenStack">OpenStack<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/智慧医疗/" title="智慧医疗">智慧医疗<sup>1</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
          <li>
            
            	<a href="http://weibo.com/jiayou087" target="_blank" title="刘兴的微博主页">微博</a>
            
          </li>
        
          <li>
            
            	<a href="http://blog.csdn.net/pangjiuzala" target="_blank" title="刘兴的CSDN博客">CSDN</a>
            
          </li>
        
    </ul>
</div>

  


  
  <div class="archiveslist">
    <p class="asidetitle"><a href="/archives">归档</a></p>
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/07/">July 2015</a><span class="archive-list-count">22</span></li></ul>
  </div>


  <div class="rsspart">
	<a href="https://github.com/search?q=pangjiuzala&amp;type=Users" target="_blank" title="关注刘兴的github">关注</a>
</div>

</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello,I&#39;m from ZjuCs! <br/>
			The more you diligent, the more you lucky!</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		
		
		
		
		
		
		
		
		
	</div>
			
		

		<p class="copyright">
		Copyright@ 2015 Liuxing All rights reserved.
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  c.click(function(){
    ta.css('display', 'block').addClass('fadeIn');
  });
  o.click(function(){
    ta.css('display', 'none');
  });
  $(window).scroll(function(){
    ta.css("top",Math.max(140,320-$(this).scrollTop()));
  });
});
</script>




<script type="text/javascript">
  var duoshuoQuery = {short_name:"pangjiuzala"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
    || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
</script> 







<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->

<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'null', 'null');  
ga('send', 'pageview');
</script>



<script type="text/javascript">
var _bdhmProtocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cscript src='" + _bdhmProtocol + "hm.baidu.com/h.js%3Ffeafc504b70a541dd3845d467335f367' type='text/javascript'%3E%3C/script%3E"));
</script>



<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_null'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s23.cnzz.com/z_stat.php%3Fid%3Dnull' type='text/javascript'%3E%3C/script%3E"));</script>

<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<script>
var option = {
  engineKey: '4ac092ad8d749fdc6293'
};
(function(w,d,t,u,n,s,e){
  s = d.createElement(t);
  s.src = u;
  s.async = 1;
  w[n] = function(r){
    w[n].opts = r;
  };
  e = d.getElementsByTagName(t)[0];
  e.parentNode.insertBefore(s, e);
})(window,document,'script','//tinysou-cdn.b0.upaiyun.com/ts.js','_ts');
_ts(option);
</script>

<!-- Tiny_search End -->

  </body>
</html>
