
 <!DOCTYPE HTML>
<html >
<head>
  <meta charset="UTF-8">
  
    <title>分类算法 | 刘兴的博客</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="刘兴">
    

    
    <meta name="description" content="本文总结了数据挖掘以及机器学习中常见算法如神经网络算法、随机森林算法以及决策树等，希望能对数据挖掘爱好者有一定帮助。">
<meta property="og:type" content="article">
<meta property="og:title" content="分类算法">
<meta property="og:url" content="http://pangjiuzala.github.io/2015/07/31/分类算法/index.html">
<meta property="og:site_name" content="刘兴的博客">
<meta property="og:description" content="本文总结了数据挖掘以及机器学习中常见算法如神经网络算法、随机森林算法以及决策树等，希望能对数据挖掘爱好者有一定帮助。">
<meta property="og:image" content="http://7xiur2.com1.z0.glb.clouddn.com/0063.png">
<meta property="og:image" content="http://7xiur2.com1.z0.glb.clouddn.com/0064.png">
<meta property="og:image" content="http://7xiur2.com1.z0.glb.clouddn.com/0065.jpg">
<meta property="og:image" content="http://7xiur2.com1.z0.glb.clouddn.com/0066.png">
<meta property="og:image" content="http://7xiur2.com1.z0.glb.clouddn.com/0067.png">
<meta property="og:image" content="http://7xiur2.com1.z0.glb.clouddn.com/0068.png">
<meta property="og:image" content="http://7xiur2.com1.z0.glb.clouddn.com/0069.png">
<meta property="og:image" content="http://7xiur2.com1.z0.glb.clouddn.com/0070.png">
<meta property="og:image" content="http://7xiur2.com1.z0.glb.clouddn.com/0071.png">
<meta property="og:image" content="http://7xiur2.com1.z0.glb.clouddn.com/0073.png">
<meta property="og:updated_time" content="2015-08-04T08:17:00.013Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="分类算法">
<meta name="twitter:description" content="本文总结了数据挖掘以及机器学习中常见算法如神经网络算法、随机森林算法以及决策树等，希望能对数据挖掘爱好者有一定帮助。">

    
    <link rel="alternative" href="https://github.com/search?q=pangjiuzala&type=Users" title="刘兴的博客" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css" type="text/css">
</head>

  <body>
    <header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.png" alt="刘兴的博客" title="刘兴的博客"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="刘兴的博客">刘兴的博客</a></h1>
				<h2 class="blog-motto"></h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">主页</a></li>
					
						<li><a href="/archives">文章列表</a></li>
					
					<li>
 					
					<form class="search" action="/search/index.html" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" autocomplete="off" name="q" maxlength="20" placeholder="搜索" />
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
  
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2015/07/31/分类算法/" title="分类算法" itemprop="url">分类算法</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="刘兴" target="_blank" itemprop="author">刘兴</a>
		
  <p class="article-time">
    <time datetime="2015-07-30T23:00:14.000Z" itemprop="datePublished"> 发表于 2015-07-31</time>
    
  </p>
</header>
	<div class="article-content">
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">文章目录</strong>
		
			<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#神经网络算法"><span class="toc-number">1.</span> <span class="toc-text">神经网络算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#简介"><span class="toc-number">1.1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#神经网络"><span class="toc-number">1.2.</span> <span class="toc-text">神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#人工神经网络"><span class="toc-number">1.3.</span> <span class="toc-text">人工神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#工作原理"><span class="toc-number">1.4.</span> <span class="toc-text">工作原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#BP神经网络模型"><span class="toc-number">1.5.</span> <span class="toc-text">BP神经网络模型</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#决策树"><span class="toc-number">2.</span> <span class="toc-text">决策树</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#简介-1"><span class="toc-number">2.1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#组成"><span class="toc-number">2.2.</span> <span class="toc-text">组成</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#画法"><span class="toc-number">2.3.</span> <span class="toc-text">画法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#决策树的剪枝"><span class="toc-number">2.4.</span> <span class="toc-text">决策树的剪枝</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#决策树的应用"><span class="toc-number">2.5.</span> <span class="toc-text">决策树的应用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#树的投票"><span class="toc-number">2.5.1.</span> <span class="toc-text">树的投票</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#一个映射的例子"><span class="toc-number">2.5.2.</span> <span class="toc-text">一个映射的例子</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#特征属性计算方法"><span class="toc-number">3.</span> <span class="toc-text">特征属性计算方法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#PageRank"><span class="toc-number">3.1.</span> <span class="toc-text">PageRank</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#TrustRank"><span class="toc-number">3.2.</span> <span class="toc-text">TrustRank</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#BadRank"><span class="toc-number">3.3.</span> <span class="toc-text">BadRank</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#K-core"><span class="toc-number">3.4.</span> <span class="toc-text">K-core</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#分类器训练方法"><span class="toc-number">4.</span> <span class="toc-text">分类器训练方法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#决策树-1"><span class="toc-number">4.1.</span> <span class="toc-text">决策树</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#朴素贝叶斯方法（NBC模型）"><span class="toc-number">4.2.</span> <span class="toc-text">朴素贝叶斯方法（NBC模型）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#随机森林"><span class="toc-number">4.3.</span> <span class="toc-text">随机森林</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#AdaBoost"><span class="toc-number">4.4.</span> <span class="toc-text">AdaBoost</span></a></li></ol></li></ol>
		
		</div>
		
		<p>本文总结了数据挖掘以及机器学习中常见算法如神经网络算法、随机森林算法以及决策树等，希望能对数据挖掘爱好者有一定帮助。<br><a id="more"></a></p>
<h1 id="神经网络算法">神经网络算法</h1><h2 id="简介">简介</h2><p>逻辑性的思维是指根据逻辑规则进行推理的过程；它先将信息化成概念，并用符号表示，然后，根据符号运算按串行模式进行逻辑推理；这一过程可以写成串行的指令，让计算机执行。然而，直观性的思维是将分布式存储的信息综合起来，结果是忽然间产生想法或解决问题的办法。这种思维方式的根本之点在于以下两点：1.信息是通过神经元上的兴奋模式分布储在网络上；2.信息处理是通过神经元之间同时相互作用的动态过程来完成的。</p>
<h2 id="神经网络">神经网络</h2><p>思维学普遍认为，人类大脑的思维分为抽象（逻辑）思维、形象（直观）思维和灵感（顿悟）思维三种基本方式。<br>人工神经网络就是模拟人思维的第二种方式。这是一个非线性动力学系统，其特色在于信息的分布式存储和并行协同处理。虽然单个神经元的结构极其简单，功能有限，但大量神经元构成的网络系统所能实现的行为却是极其丰富多彩的。<br>神经网络的研究内容相当广泛，反映了多学科交叉技术领域的特点。主要的研究工作集中在以下几个方面：<br>（1）生物原型研究。从生理学、心理学、解剖学、脑科学、病理学等生物科学方面研究神经细胞、神经网络、神经系统的生物原型结构及其功能机理。<br>（2）建立理论模型。根据生物原型的研究，建立神经元、神经网络的理论模型。其中包括概念模型、知识模型、物理化学模型、数学模型等。<br>（3）网络模型与算法研究。在理论模型研究的基础上构作具体的神经网络模型，以实现计算机模拟或准备制作硬件，包括网络学习算法的研究。这方面的工作也称为技术模型研究。<br>（4）人工神经网络应用系统。在网络模型与算法研究的基础上，利用人工神经网络组成实际的应用系统，例如，完成某种信号处理或模式识别的功能、构造专家系统、制成机器人等等。<br>纵观当代新兴科学技术的发展历史，人类在征服宇宙空间、基本粒子，生命起源等科学技术领域的进程中历经了崎岖不平的道路。我们也会看到，探索人脑功能和神经网络的研究将伴随着重重困难的克服而日新月异。</p>
<h2 id="人工神经网络">人工神经网络</h2><p>人工神经网络（ArtificialNeuralNetworks，ANN）系统是20世纪40年代后出现的。它是由众多的神经元可调的连接权值连接而成，具有大规模并行处理、分布式信息存储、良好的自组织自学习能力等特点。BP（BackPropagation）算法又称为误差反向传播算法，是人工神经网络中的一种监督式的学习算法。BP神经网络算法在理论上可以逼近任意函数，基本的结构由非线性变化单元组成，具有很强的非线性映射能力。而且网络的中间层数、各层的处理单元数及网络的学习系数等参数可根据具体情况设定，灵活性很大，在优化、信号处理与模式识别、智能控制、故障诊断等许多领域都有着广泛的应用前景。</p>
<h2 id="工作原理">工作原理</h2><p>人工神经网络是由大量的简单基本元件——神经元相互联接而成的自适应非线性动态系统。每个神经元的结构和功能比较简单，但大量神经元组合产生的系统行为却非常复杂。<br>人工神经网络反映了人脑功能的若干基本特性，但并非生物系统的逼真描述，只是某种模仿、简化和抽象。<br>与数字计算机比较，人工神经网络在构成原理和功能特点等方面更加接近人脑，它不是按给定的程序一步一步地执行运算，而是能够自身适应环境、总结规律、完成某种运算、识别或过程控制。<br>人工神经网络首先要以一定的学习准则进行学习，然后才能工作。现以人工神经网络对于写“A”、“B”两个字母的识别为例进行说明，规定当“A”输入网络时，应该输出“1”，而当输入为“B”时，输出为“0”。<br>所以网络学习的准则应该是：如果网络作出错误的的判决，则通过网络的学习，应使得网络减少下次犯同样错误的可能性。首先，给网络的各连接权值赋予(0，1)区间内的随机值，将“A”所对应的图象模式输入给网络，网络将输入模式加权求和、与门限比较、再进行非线性运算，得到网络的输出。在此情况下，网络输出为“1”和“0”的概率各为50%，也就是说是完全随机的。这时如果输出为“1”(结果正确)，则使连接权值增大，以便使网络再次遇到“A”模式输入时，仍然能作出正确的判断。<br>如果输出为“0”(即结果错误)，则把网络连接权值朝着减小综合输入加权值的方向调整，其目的在于使网络下次再遇到“A”模式输入时，减小犯同样错误的可能性。如此操作调整，当给网络轮番输入若干个手写字母“A”、“B”后，经过网络按以上学习方法进行若干次学习后，网络判断的正确率将大大提高。这说明网络对这两个模式的学习已经获得了成功，它已将这两个模式分布地记忆在网络的各个连接权值上。当网络再次遇到其中任何一个模式时，能够作出迅速、准确的判断和识别。一般说来，网络中所含的神经元个数越多，则它能记忆、识别的模式也就越多。<br>特点<br>（1）普通计算机的功能取决于程序中给出的知识和能力。显然，对于智能活动要通过总结编制程序将十分困难。<br>人工神经网络也具有初步的自适应与自组织能力。在学习或训练过程中改变突触权重值，以适应周围环境的要求。同一网络因学习方式及内容不同可具有不同的功能。人工神经网络是一个具有学习能力的系统，可以发展知识，以致超过设计者原有的知识水平。通常，它的学习训练方式可分为两种，一种是有监督或称有导师的学习，这时利用给定的样本标准进行分类或模仿；另一种是无监督学习或称无为导师学习，这时，只规定学习方式或某些规则，则具体的学习内容随系统所处环境（即输入信号情况）而异，系统可以自动发现环境特征和规律性，具有更近似人脑的功能。<br>（2）泛化能力<br>泛化能力指对没有训练过的样本，有很好的预测能力和控制能力。特别是，当存在一些有噪声的样本，网络具备很好的预测能力。<br>(3)非线性映射能力<br>当对系统对于设计人员来说，很透彻或者很清楚时，则一般利用数值分析，偏微分方程等数学工具建立精确的数学模型，但当对系统很复杂，或者系统未知，系统信息量很少时，建立精确的数学模型很困难时，神经网络的非线性映射能力则表现出优势，因为它不需要对系统进行透彻的了解，但是同时能达到输入与输出的映射关系，这就大大简化设计的难度。<br>(4)高度并行性<br>并行性具有一定的争议性。承认具有并行性理由：神经网络是根据人的大脑而抽象出来的数学模型，由于人可以同时做一些事，所以从功能的模拟角度上看，神经网络也应具备很强的并行性。<br>下面将人工神经网络与通用的计算机工作特点来对比一下：<br>若从速度的角度出发，人脑神经元之间传递信息的速度要远低于计算机，前者为毫秒量级，而后者的频率往往可达几百兆赫。但是，由于人脑是一个大规模并行与串行组合处理系统，因而，在许多问题上可以作出快速判断、决策和处理，其速度则远高于串行结构的普通计算机。人工神经网络的基本结构模仿人脑，具有并行处理特征，可以大大提高工作速度。<br>人脑存贮信息的特点为利用突触效能的变化来调整存贮内容，也即信息存贮在神经元之间连接强度的分布上，存贮区与计算机区合为一体。虽然人脑每日有大量神经细胞死亡（平均每小时约一千个），但不影响大脑的正常思维活动。<br>普通计算机是具有相互独立的存贮器和运算器，知识存贮与数据运算互不相关，只有通过人编出的程序使之沟通，这种沟通不能超越程序编制者的预想。元器件的局部损坏及程序中的微小错误都可能引起严重的失常。</p>
<h2 id="BP神经网络模型">BP神经网络模型</h2><p>BP网络能学习和存贮大量的输入-输出模式映射关系，而无需事前揭示描述这种映射关系的数学方程。它的学习规则是使用最速下降法，通过反向传播来不断调整网络的权值和阈值，使网络的误差平方和最小。BP神经网络模型拓扑结构包括输入层（input）、隐层(hidelayer)和输出层(outputlayer)。BP神经网络算法是在BP神经网络现有算法的基础上提出的，是通过任意选定一组权值，将给定的目标输出直接作为线性方程的代数和来建立线性方程组，解得待求权，不存在传统方法的局部极小及收敛速度慢的问题，且更易理解。<br>其基本思想是：由所给的输入、输出模式对通过作用于神经网络来建立线性方程组，运用高斯消元法解线性方程组来求得未知权值，而未采用传统BP网络的非线性函数误差反馈寻优的思想。<br>对给定的样本模式对，随机选定一组自由权，作为输出层和隐含层之间固定权值，通过传递函数计算隐层的实际输出，再将输出层与隐层间的权值作为待求量，直接将目标输出作为等式的右边建立方程组来求解。</p>
<h1 id="决策树">决策树</h1><h2 id="简介-1">简介</h2><p>项目风险，判断其可行性的决策分析方法，是直观运用概率分析的一种图解法。由于这种决策分支画成图形很像一棵树的枝干，故称决策树。在机器学习中，决策树是一个预测模型，他代表的是对象属性与对象值之间的一种映射关系。Entropy=系统的凌乱程度，使用算法ID3, C4.5和C5.0生成树算法使用熵。这一度量是基于信息学理论中熵的概念。<br>决策树是一种树形结构，其中每个内部节点表示一个属性上的测试，每个分支代表一个测试输出，每个叶节点代表一种类别。<br>分类树（决策树）是一种十分常用的分类方法。他是一种监管学习，所谓监管学习就是给定一堆样本，每个样本都有一组属性和一个类别，这些类别是事先确定的，那么通过学习得到一个分类器，这个分类器能够对新出现的对象给出正确的分类。这样的机器学习就被称之为监督学习。</p>
<h2 id="组成">组成</h2><p>□——决策点，是对几种可能方案的选择，即最后选择的最佳方案。如果决策属于多级决策，则决策树的中间可以有多个决策点，以决策树根部的决策点为最终决策方案。<br>○——状态节点，代表备选方案的经济效果（期望值），通过各状态节点的经济效果的对比，按照一定的决策标准就可以选出最佳方案。由状态节点引出的分支称为概率枝，概率枝的数目表示可能出现的自然状态数目每个分枝上要注明该状态出现的概率。<br>△——结果节点，将每个方案在各种自然状态下取得的损益值标注于结果节点的右端。</p>
<h2 id="画法">画法</h2><p>机器学习中，决策树是一个预测模型；他代表的是对象属性与对象值之间的一种映射关系。树中每个节点表示某个对象，而每个分叉路径则代表的某个可能的属性值，而每个叶结点则对应从根节点到该叶节点所经历的路径所表示的对象的值。决策树仅有单一输出，若欲有复数输出，可以建立独立的决策树以处理不同输出。数据挖掘中决策树是一种经常要用到的技术，可以用于分析数据，同样也可以用来作预测。<br>从数据产生决策树的机器学习技术叫做决策树学习,通俗说就是决策树。<br>一个决策树包含三种类型的节点：<br>决策节点：通常用矩形框来表示<br>机会节点：通常用圆圈来表示<br>终结点：通常用三角形来表示<br>决策树学习也是资料探勘中一个普通的方法。在这里，每个决策树都表述了一种树型结构，它由它的分支来对该类型的对象依靠属性进行分类。每个决策树可以依靠对源数据库的分割进行数据测试。这个过程可以递归式的对树进行修剪。当不能再进行分割或一个单独的类可以被应用于某一分支时，递归过程就完成了。另外，随机森林分类器将许多决策树结合起来以提升分类的正确率。<br>决策树同时也可以依靠计算条件概率来构造。<br>决策树如果依靠数学的计算方法可以取得更加理想的效果。数据库已如下所示：<br>　　(x,y)=(x1,x2,x3…,xk,y)<br>相关的变量Y表示我们尝试去理解，分类或者更一般化的结果。其他的变量x1,x2,x3等则是帮助我们达到目的的变量。<br>决策树实际上是将空间用超平面进行划分的一种方法，每次分割的时候，都将当前的空间一分为二，比如说下面的决策树：</p>
<center><br><img src="http://7xiur2.com1.z0.glb.clouddn.com/0063.png" alt=""><br></center><br>就是将空间划分成下面的样子：<br><center><br><img src="http://7xiur2.com1.z0.glb.clouddn.com/0064.png" alt=""><br></center>


<h2 id="决策树的剪枝">决策树的剪枝</h2><p>剪枝是决策树停止分支的方法之一，剪枝有分预先剪枝和后剪枝两种。预先剪枝是在树的生长过程中设定一个指标，当达到该指标时就停止生长，这样做容易产生“视界局限”，就是一旦停止分支，使得节点N成为叶节点，就断绝了其后继节点进行“好”的分支操作的任何可能性。不严格的说这些已停止的分支会误导学习算法，导致产生的树不纯度降差最大的地方过分靠近根节点。后剪枝中树首先要充分生长，直到叶节点都有最小的不纯度值为止，因而可以克服“视界局限”。然后对所有相邻的成对叶节点考虑是否消去它们，如果消去能引起令人满意的不纯度增长，那么执行消去，并令它们的公共父节点成为新的叶节点。这种“合并”叶节点的做法和节点分支的过程恰好相反，经过剪枝后叶节点常常会分布在很宽的层次上，树也变得非平衡。后剪枝技术的优点是克服了“视界局限”效应，而且无需保留部分样本用于交叉验证，所以可以充分利用全部训练集的信息。但后剪枝的计算量代价比预剪枝方法大得多，特别是在大样本集中，不过对于小样本的情况，后剪枝方法还是优于预剪枝方法的。</p>
<h2 id="决策树的应用">决策树的应用</h2><p>某公司承担一段铁路维修任务，现因进入雨季，需要停工三个月，在停工期间如果搬走机械，需搬运费1800元，如果将机械留在原处，一种方案是花500元做防护措施，防止雨水浸泡机械，如不做防护措施，发生雨水浸泡时将损失10000元，如下暴雨发生洪水时，则不管是否有防护措施，施工机械留在原处都将受到60000元得损失，根据资料，该地区夏季高水位的发生率是25%，洪水的发生率是2%，请问:试用决策树法分析该公司施工队要不要搬走施工机械以及要不要做防护措施？<br>1.绘制决策树，见图。</p>
<center><br><img src="http://7xiur2.com1.z0.glb.clouddn.com/0065.jpg" alt=""><br></center><br>2.计算期望值。<br>状态点2的期望值：0<br>状态点3的期望值：(-60000) ×0.02 = -1200(元)<br>状态点4的期望值：(-60000) ×0.02 + (-10000) ×0.25 = -3700(元)<br>3.选择损失最小的方案。<br>min{(0-1800),(-1200-500),(-3700-0)}=-1700(元)<br>以不搬走施工机械并作好防护措施最为合算。<br>##决策树优化——随机森林<br>随机森林是一个高度灵活的机器学习方法，拥有广泛的应用前景，从市场营销到医疗保健保险。既可以用来做市场营销模拟的建模，统计客户来源，保留和流失。也可用来预测疾病的风险和病患者的易感性。<br>    随机森林是一个可做能够回归和分类。它具备处理大数据的特性，而且它有助于估计或变量是非常重要的基础数据建模。<br>###随机决策树<br>我们知道随机森林是其他的模型聚合，但它聚合了什么类型模型？你可能已经从其名称、随机森林聚合分类（或回归）的树中猜到。决策树是由一系列的决策的组合，可用于分类观察数据集。<br>###随机森林<br>算法引入了一个随机森林来自动创建随机决策树群。由于树随机生成的树，大部分的树(或许99.9%树)不会对学习的分类/回归问题都有意义。<br><center><br><img src="http://7xiur2.com1.z0.glb.clouddn.com/0066.png" alt=""><br></center>

<p>如果观察到长度为45，蓝眼睛，和2条腿，就被归类为 红色 。</p>
<h3 id="树的投票">树的投票</h3><p>   当你要做预测的时候，新的观察到的特征随着决策树自上而下走下来，这样一组观察到的特征将会被贴上一个预测值/标签。一旦森林中的每棵树都给出了预测值/标签，所有的预测结果将被归总到一起，所有树的模式投票被返回做为最终的预测结果。<br>   简单来说，99.9%不相关的树做出的预测结果涵盖所有的情况，这些预测结果将会彼此抵消。少数优秀的树的预测结果将会超脱于芸芸“噪音”，做出一个好的预测。</p>
<center><br><img src="http://7xiur2.com1.z0.glb.clouddn.com/0067.png" alt=""><br></center>

<h3 id="一个映射的例子">一个映射的例子</h3><p>随机森林在没有精心准备的数据映射的情况下也能学习。以方程f(x) = log(x)为例。制造一些假数据，并且加上一点儿噪音。</p>
<figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">import numpy as np    x = np<span class="class">.random</span><span class="class">.uniform</span>(<span class="number">1</span>, <span class="number">100</span>, <span class="number">1000</span>)    y = np.<span class="function"><span class="title">log</span><span class="params">(x)</span></span> + np<span class="class">.random</span><span class="class">.normal</span>(<span class="number">0</span>, .<span class="number">3</span>, <span class="number">1000</span>)</span><br></pre></td></tr></table></figure>
<center><br><img src="http://7xiur2.com1.z0.glb.clouddn.com/0068.png" alt=""><br></center>



<p>如果我们建立了一个基本的线性模型通过使用 x 来预测y，我们需要作一条直线，算是平分log (x)函数。而如果我们使用一个随机的森林，它不会更好的逼近 log (x)曲线并能够使得它更像实际函数。 </p>
<center><br><img src="http://7xiur2.com1.z0.glb.clouddn.com/0069.png" alt=""><br></center><br>你也许会说随机森林有点扰乱log(x)函数。不管怎样我都认为这做了一个很好的说明如何随机森林并未绑定于线性约束 。<br>变量选择<br>随机森林最好的用例之一是特征选择。尝试很多决策树变种的一个副产品就是你可以检测每棵树中哪个变量最合适/最糟糕。<br>当一棵树使用一个变量，而另一棵不使用这个变量，你就可以从是否包含这个变量来比较价值的减少或增加。优秀的随机森林实现将为你做这些事情，所以你需要做的仅仅是知道去看那个方法或参数。<br>在下述的例子中，我们尝试去指出对于将酒分为红酒或者白酒哪个变量是最重要的。<br><center><br><img src="http://7xiur2.com1.z0.glb.clouddn.com/0070.png" alt=""><br></center><br><center><br><img src="http://7xiur2.com1.z0.glb.clouddn.com/0071.png" alt=""><br></center><br>回归<br>是的，它也可以做回归。<br>我们已经发现随机森林——不像其它算法——对分类变量或者分类变量和真实变量混合学习的非常好。具有高基数（可能值的#）的分类变量是很棘手的，所以在你的口袋中放点儿这样的东西将会是非常有用的。<br>一个简短的python例子<br>cikit-Learn是开始使用随机森林的一个很好的方式。scikit-learn API在所以算法中极其的一致，所有你测试和在不同的模型间切换非常容易。很多时候，我从一些简单的东西开始，然后转移到了随机森林。 随机森林在scikit-learn中的实现最棒的特性是n_jobs参数。这将会基于你想使用的核数自动地并行设置随机森林。这里是scikit-learn的贡献者Olivier Grisel的一个很棒的报告，在这个报告中他谈论了使用20个节点的EC2集群训练随机森林。<br><figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">from sklearn<span class="class">.datasets</span> import load_iris</span><br><span class="line">from sklearn<span class="class">.ensemble</span> import RandomForestClassifier</span><br><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line"> </span><br><span class="line">iris = <span class="function"><span class="title">load_iris</span><span class="params">()</span></span></span><br><span class="line">df = pd.<span class="function"><span class="title">DataFrame</span><span class="params">(iris.data, columns=iris.feature_names)</span></span></span><br><span class="line">df[<span class="string">'is_train'</span>] = np<span class="class">.random</span><span class="class">.uniform</span>(<span class="number">0</span>, <span class="number">1</span>, <span class="function"><span class="title">len</span><span class="params">(df)</span></span>) &lt;= .<span class="number">75</span></span><br><span class="line">df[<span class="string">'species'</span>] = pd.<span class="function"><span class="title">Factor</span><span class="params">(iris.target, iris.target_names)</span></span></span><br><span class="line">df.<span class="function"><span class="title">head</span><span class="params">()</span></span></span><br><span class="line"> </span><br><span class="line">train, test = df[df[<span class="string">'is_train'</span>]==True], df[df[<span class="string">'is_train'</span>]==False]</span><br><span class="line"> </span><br><span class="line">features = df<span class="class">.columns</span>[:<span class="number">4</span>]</span><br><span class="line">clf = <span class="function"><span class="title">RandomForestClassifier</span><span class="params">(n_jobs=<span class="number">2</span>)</span></span></span><br><span class="line">y, _ = pd.<span class="function"><span class="title">factorize</span><span class="params">(train[<span class="string">'species'</span>])</span></span></span><br><span class="line">clf.<span class="function"><span class="title">fit</span><span class="params">(train[features], y)</span></span></span><br><span class="line"> </span><br><span class="line">preds = iris<span class="class">.target_names</span>[clf.<span class="function"><span class="title">predict</span><span class="params">(test[features])</span></span>]</span><br><span class="line">pd.<span class="function"><span class="title">crosstab</span><span class="params">(test[<span class="string">'species'</span>], preds, rownames=[<span class="string">'actual'</span>], colnames=[<span class="string">'preds'</span>])</span></span></span><br></pre></td></tr></table></figure><br><br><center><br><img src="http://7xiur2.com1.z0.glb.clouddn.com/0073.png" alt=""><br></center>

<p>随机森林相当容易使用，而且很强大。对于任何建模，都要注意过拟合。如果你有兴趣用R语言开始使用随机森林，那么就签出randomForest包。</p>
<h1 id="特征属性计算方法">特征属性计算方法</h1><h2 id="PageRank">PageRank</h2><p>利用网页间的链接信息，计算该网页的重要性得分。指向它的页面和它链接的网页数量越多，分数越高，该页面本身的得分也越高。体现了网页的相关性和重要性<br>本模型中指一个卖家或者买家参加交易的次数越多，得分越高<br>缺点是容易伪造大量垃圾页面来刷分数。同理，卖家可以伪造虚假买家来刷分</p>
<h2 id="TrustRank">TrustRank</h2><p>由于用PageRank计算时，网页链接的数量很重要。所以会产生很多垃圾页面去链接来刷分数。TrustRank可以用来检测垃圾网站，并给出网页的得分。体现了网页的信任度。<br>优质的网页会经常链接到其他一些优质的网页，而很少指向垃圾网页。同理，优质的买家和卖家之间也有这种关系。</p>
<h2 id="BadRank">BadRank</h2><p>指向垃圾页面的页面通常也是垃圾页面。计算方法和TrustRank类似。</p>
<h2 id="K-core">K-core</h2><p>一种聚类算法。从复杂的社交网络中提取高度相关的子结构（紧密子图），分析大规模的网络模型，一个顶点的k-core值越大表示该顶点处于图的密集处。<br>通过计算每个实体的k-core值，可以用来分析买家或卖家之间行为异常的团伙。</p>
<h1 id="分类器训练方法">分类器训练方法</h1><h2 id="决策树-1">决策树</h2><p>分类算法。通过已有的数据构建分类器来对未知的数据进行分类。<br>缺点是容易过度拟合，即对训练的数据表现不错，但是对未知数据有较高的错误率。可以用随机森林算法来优化。</p>
<h2 id="朴素贝叶斯方法（NBC模型）">朴素贝叶斯方法（NBC模型）</h2><p>分类算法。通过贝叶斯定理计算每个类别的概率，选取概率最大的分类。<br>在属性个数比较多或者属性之间相关性较大时，NBC模型的分类效率比不上决策树模型。而在属性相关性较小时，NBC模型的性能最为良好。</p>
<h2 id="随机森林">随机森林</h2><p>分类优化算法。用训练数据随机生成很多决策树，形成森林，用森林对未知数据进行分类，选取最多的分类作为最终的分类。<br>可以提高类不平衡数据的分类准确度。在我们模型中，欺诈情况要比非欺诈情况少的多，属于类不平衡数据。</p>
<h2 id="AdaBoost">AdaBoost</h2><p>分类优化算法。使用多个弱分类器组合得到强分类器的算法。<br>使用已有的简单分类器对样本进行分类，加大分类错误样本点的权值。重复进行上面步骤，并且不断迭代，得到最终效果较好的强分类器。</p>
  
	</div>
		<footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/数据挖掘/">数据挖掘</a><a href="/tags/算法/">算法</a>
  </div>

</div>



	<div class="article-share" id="share">
	
	<div class="share-jiathis">
	  
<div class="jiathis_style_24x24">
	<a class="jiathis_button_tsina"></a>
	<a class="jiathis_button_weixin"></a>
	<a class="jiathis_button_renren"></a>
	<a class="jiathis_button_qzone"></a>
	<a class="jiathis_button_googleplus"></a>
	<a class="jiathis_button_douban"></a>
	<a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" >
    var jiathis_config={
    data_track_clickback:true,
    sm:"copy,renren,cqq",
    pic:"",
    summary:"",
    
  </script> 
<script type="text/javascript" src="//v3.jiathis.com/code/jia.js?uid=
" charset="utf-8"></script>      

	 </div>
	
	</div>


</footer>

   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2015/08/01/一种面向高维数据的集成聚类算法/" title="一种面向高维数据的集成聚类算法">
  <strong>上一篇：</strong><br/>
  <span>
  一种面向高维数据的集成聚类算法</span>
</a>
</div>


<div class="next">
<a href="/2015/07/30/数据挖掘笔记/"  title="数据挖掘笔记">
 <strong>下一篇：</strong><br/> 
 <span>数据挖掘笔记
</span>
</a>
</div>

</nav>

	
<section id="comments" class="comment">
	<div class="ds-thread" data-thread-key="2015/07/31/分类算法/" data-title="分类算法" data-url="http://pangjiuzala.github.io/2015/07/31/分类算法/"></div>
</section>


</div>  
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">文章目录</strong>
 
 <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#神经网络算法"><span class="toc-number">1.</span> <span class="toc-text">神经网络算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#简介"><span class="toc-number">1.1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#神经网络"><span class="toc-number">1.2.</span> <span class="toc-text">神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#人工神经网络"><span class="toc-number">1.3.</span> <span class="toc-text">人工神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#工作原理"><span class="toc-number">1.4.</span> <span class="toc-text">工作原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#BP神经网络模型"><span class="toc-number">1.5.</span> <span class="toc-text">BP神经网络模型</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#决策树"><span class="toc-number">2.</span> <span class="toc-text">决策树</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#简介-1"><span class="toc-number">2.1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#组成"><span class="toc-number">2.2.</span> <span class="toc-text">组成</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#画法"><span class="toc-number">2.3.</span> <span class="toc-text">画法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#决策树的剪枝"><span class="toc-number">2.4.</span> <span class="toc-text">决策树的剪枝</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#决策树的应用"><span class="toc-number">2.5.</span> <span class="toc-text">决策树的应用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#树的投票"><span class="toc-number">2.5.1.</span> <span class="toc-text">树的投票</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#一个映射的例子"><span class="toc-number">2.5.2.</span> <span class="toc-text">一个映射的例子</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#特征属性计算方法"><span class="toc-number">3.</span> <span class="toc-text">特征属性计算方法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#PageRank"><span class="toc-number">3.1.</span> <span class="toc-text">PageRank</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#TrustRank"><span class="toc-number">3.2.</span> <span class="toc-text">TrustRank</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#BadRank"><span class="toc-number">3.3.</span> <span class="toc-text">BadRank</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#K-core"><span class="toc-number">3.4.</span> <span class="toc-text">K-core</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#分类器训练方法"><span class="toc-number">4.</span> <span class="toc-text">分类器训练方法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#决策树-1"><span class="toc-number">4.1.</span> <span class="toc-text">决策树</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#朴素贝叶斯方法（NBC模型）"><span class="toc-number">4.2.</span> <span class="toc-text">朴素贝叶斯方法（NBC模型）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#随机森林"><span class="toc-number">4.3.</span> <span class="toc-text">随机森林</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#AdaBoost"><span class="toc-number">4.4.</span> <span class="toc-text">AdaBoost</span></a></li></ol></li></ol>
 
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  <div class="weiboshow">
  <p class="asidetitle">新浪微博</p>
    <iframe width="100%" height="119" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=119&fansRow=2&ptype=1&speed=0&skin=9&isTitle=1&noborder=1&isWeibo=0&isFans=0&uid=2129798793&verifier=c0951e84&dpc=1"></iframe>
</div>


  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/Java/" title="Java">Java<sup>10</sup></a></li>
			
		
			
				<li><a href="/tags/算法/" title="算法">算法<sup>5</sup></a></li>
			
		
			
				<li><a href="/tags/大数据/" title="大数据">大数据<sup>5</sup></a></li>
			
		
			
				<li><a href="/tags/Hadoop/" title="Hadoop">Hadoop<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/数据挖掘/" title="数据挖掘">数据挖掘<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/移动互联网/" title="移动互联网">移动互联网<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/物联网/" title="物联网">物联网<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/Android/" title="Android">Android<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/云平台/" title="云平台">云平台<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/云计算/" title="云计算">云计算<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/设计模式/" title="设计模式">设计模式<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Python/" title="Python">Python<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/网络爬虫/" title="网络爬虫">网络爬虫<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/操作系统/" title="操作系统">操作系统<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/OpenStack/" title="OpenStack">OpenStack<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/智慧医疗/" title="智慧医疗">智慧医疗<sup>1</sup></a></li>
			
		
		</ul>
</div>


  
  <div class="archiveslist">
    <p class="asidetitle"><a href="/archives">归档</a></p>
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/08/">August 2015</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/07/">July 2015</a><span class="archive-list-count">25</span></li></ul>
  </div>


  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
          <li>
            
            	<a href="http://blog.csdn.net/pangjiuzala" target="_blank" title="刘兴的CSDN博客">CSDN</a>
            
          </li>
        
    </ul>
</div>

  <div class="rsspart">
	<a href="https://github.com/search?q=pangjiuzala&amp;type=Users" target="_blank" title="关注刘兴的github">关注</a>
</div>

  

  


</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello,I&#39;m from ZjuCs! <br/>
			The more you diligent, the more you lucky!</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		
		
		
		
		
		
		
		
		
	</div>
			
		

		<p class="copyright">
		Copyright@ 2015 Liuxing All rights reserved.
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  c.click(function(){
    ta.css('display', 'block').addClass('fadeIn');
  });
  o.click(function(){
    ta.css('display', 'none');
  });
  $(window).scroll(function(){
    ta.css("top",Math.max(140,320-$(this).scrollTop()));
  });
});
</script>




<script type="text/javascript">
  var duoshuoQuery = {short_name:"pangjiuzala"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
    || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
</script> 







<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->

<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'null', 'null');  
ga('send', 'pageview');
</script>



<script type="text/javascript">
var _bdhmProtocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cscript src='" + _bdhmProtocol + "hm.baidu.com/h.js%3Ffeafc504b70a541dd3845d467335f367' type='text/javascript'%3E%3C/script%3E"));
</script>



<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_null'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s23.cnzz.com/z_stat.php%3Fid%3Dnull' type='text/javascript'%3E%3C/script%3E"));</script>

<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<script>
var option = {
  engineKey: '4ac092ad8d749fdc6293'
};
(function(w,d,t,u,n,s,e){
  s = d.createElement(t);
  s.src = u;
  s.async = 1;
  w[n] = function(r){
    w[n].opts = r;
  };
  e = d.getElementsByTagName(t)[0];
  e.parentNode.insertBefore(s, e);
})(window,document,'script','//tinysou-cdn.b0.upaiyun.com/ts.js','_ts');
_ts(option);
</script>

<!-- Tiny_search End -->

  </body>
</html>
